<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[OpenSensors.IO]]></title>
  <link href="http://blog.opensensors.io/atom.xml" rel="self"/>
  <link href="http://blog.opensensors.io/"/>
  <updated>2016-10-17T19:28:33+01:00</updated>
  <id>http://blog.opensensors.io/</id>
  <author>
    <name><![CDATA[OpenSensors.IO]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Tips for Installing a Community Air Quality Sensor Network]]></title>
    <link href="http://blog.opensensors.io/blog/2016/10/17/tips-for-installing-a-community-air-quality-sensor-network/"/>
    <updated>2016-10-17T19:15:00+01:00</updated>
    <id>http://blog.opensensors.io/blog/2016/10/17/tips-for-installing-a-community-air-quality-sensor-network</id>
    <content type="html"><![CDATA[<p>Small air pollution sensor technologies have enabled deployment of numerous sensors across a small geographic area that can supplement existing monitoring networks and significantly reduce the cost of longer-term community air pollution studies.This helps mitigate the risk of current approaches to monitoring air quality in a region that rely on only a dozen or so stations and may give you an average that is not be representative of what’s happening where you live.</p>

<h2>What are you trying to do</h2>

<p>Air quality is affected by many possible contaminants, in fact the Environmental Protection Agency (EPA) has identified six “criteria pollutants” as pollutants of concern because of their impacts on health and the environment . The criteria pollutants (<a href="http://www.epa.gov/airquality/urbanair/">http://www.epa.gov/airquality/urbanair/</a>)  are:</p>

<ol>
<li>ozone (O3) <a href="http://www.epa.gov/air/ozonepollution/">http://www.epa.gov/air/ozonepollution/</a></li>
<li>particulate matter (PM) <a href="http://www.epa.gov/air/particlepollution/">http://www.epa.gov/air/particlepollution/</a></li>
<li>carbon monoxide (CO)  <a href="http://www.epa.gov/airquality/carbonmonoxide/">http://www.epa.gov/airquality/carbonmonoxide/</a></li>
<li>nitrogen dioxide (NO2) <a href="http://www.epa.gov/air/nitrogenoxides/">http://www.epa.gov/air/nitrogenoxides/</a></li>
<li>sulfur dioxide (SO2) <a href="http://www.epa.gov/air/sulfurdioxide/">http://www.epa.gov/air/sulfurdioxide/</a></li>
<li>lead (Pb). <a href="http://www.epa.gov/air/lead/">http://www.epa.gov/air/lead/</a></li>
</ol>


<p>Under the Clean Air Act, the EPA has established primary and secondary National Ambient Air Quality Standards (NAAQS) for these six pollutants. As you begin, keep in mind what you want to measure and how that information will be used. Is there some final output or final report you&rsquo;ve got to get to?</p>

<h2>Understand your sensor choices for collecting air quality data</h2>

<p>Commercially available sensors can measure the level of potential contaminants including  O3, NO2, NO, SO2, CO, PM2.5 and lead.  These devices should be designed to be easy to connect and provide quality data measurements so that non technical community groups can deploy them.</p>

<p>Here are some factors to consider in assessing options for sensors to collect air quality data
* cost
* operating lifetime
* accuracy, precision,and bias of measurement
* range of sensitivity
* speed of response time
* maintenance requirements
* reliability</p>

<p>More information on what and how to measure see <a href="https://cfpub.epa.gov/si/si_public_file_download.cfm?p_download_id=519616">https://cfpub.epa.gov/si/si_public_file_download.cfm?p_download_id=519616</a></p>

<p>Beyond the sensors, you will need to make tradeoffs between cost and redundancy for the best network connectivity.</p>

<p>Point to point &ndash; lowest cost, greater number of coverage points, least redundancy for each individual point
Mesh &ndash; higher cost, greater redundancy</p>

<p>Most community-based sensor networks are adopting point-to-point network connectivity because of the ease of connection and low-cost structure. Here is a guide that we already have around pros and cons around connectivity, use that to find the best connectivity network</p>

<h2>Our Process</h2>

<p>OpenSensors recommends a phased approach, from proof of concept to full-scale deployment, to ensure a successful installation of an IoT network in a business environment. Our aim is to reduce the time to go live and minimize risk.</p>

<h3>Phase 1 Evaluate sensors:</h3>

<p>Evaluate different sensors for quality, signal-to-noise ratio, power consumption and ease of setup by trying them out on a very small scale in a lab.</p>

<h3>Phase 2 Proof of concept:</h3>

<p>Do a full end-to-end test to verify that the queries and analytics were feasible. Connect 5 to 10 sensors to a cloud infrastructure.</p>

<h3>Phase 3 Pilot phase:</h3>

<p>Move out of the lab into your actual environment. Typically, this requires somewhere between 30 to 100 sensors. We suggest a one to two-month test to ensure that the sensors work at scale and the gateway can handle the load, similar to production usage.</p>

<p>In addition to testing the sensors in the wild, this is the time to think through your onboarding process for the devices.  Questions like; who will install the sensors feeds into design decisions on the firmware of how much pre-configuration has to be done.  We recommend a ‘just works’ approach and an assumption that all sensors will be installed by people who willnot configure firmware.  If you need to deploy 200-300 sensors, the installation engineers need to be able to deploy a lot of sensors in a distributed physical environment over a short amount of time.  It is much more efficient for your sensors to be pre configured.  In these situations, we give usually give people a simple interface to enable them to add meta data such as location and elevation.  Sensors should be labelled clearly and details pre-loaded on a cloud platform like OpenSensors before they are deployed so that adding meta data information is a matter of 1-2 steps.</p>

<h3>Phase 4 Plan and implement full-scale deployment:</h3>

<p>After the pilot phase, there should be enough data to verify network performance and your choices for sensors and connectivity, after which, full deployment can be planned in detail and implemented.</p>

<p>Contact us if you would like assistance on sensor selection, network design, or planning a proof of concept deployment.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Path to Smart Buildings]]></title>
    <link href="http://blog.opensensors.io/blog/2016/10/05/path-to-smart-buildings-2/"/>
    <updated>2016-10-05T08:31:00+01:00</updated>
    <id>http://blog.opensensors.io/blog/2016/10/05/path-to-smart-buildings-2</id>
    <content type="html"><![CDATA[<p>Whether you are a building manager planning efficient space usage or an architect looking to design state-of-the-art buildings, we have broken down the steps to get you to your desired end goal. IoT planning should start with the business needs, of course, and quickly moves from the component layer all the way up to the application layer. We need to figure out what core data should be gathered and ways to effectively leverage that data. These IoT solutions require an end-to-end or device-to-cloud view.</p>

<p><img src="http://blog.opensensors.io/images/OS Path to Smart-color.png" /></p>

<h2>A Phased implementation approach works best.</h2>

<p>We have found that the most successful IoT projects follow a phased implementation approach: Design Phase, Proof of Concept, Pilot, and Deployment. The design phase asks questions such as which sensors, who will be installing and maintaining the sensors. For Proof of Concept, a lab evaluation should include hooking up 5-8 sensors all the way through a gateway to data collection in the cloud. This will give enough real data to verify that the queries and the  analytics are feasible. The Pilot Phase ensures that the sensors work at scale and that the gateway configuration has been made easy for the deployment specialists. A pilot phase should be about 40 sensors depending on the density of the sensors. At this point, you can scale up to the number of sensors and the bandwidth required for full deployment.</p>

<h2>OpenSensors&#8217; Deployments</h2>

<p>We have built hardware, installation and network provider partnerships and relationships to help customers get rollouts live efficiently. Either roll out your own network or we will put you in touch with your local sensor installation specialist to take care of the install and maintenance.  We are working with customers and the community to understand what is required at each level for your IoT solution and can ease development and integration issues.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Lessons Learned From First Generation IoT Installations]]></title>
    <link href="http://blog.opensensors.io/blog/2016/09/09/lessons-learned-from-first-generation-iot-installations/"/>
    <updated>2016-09-09T08:06:00+01:00</updated>
    <id>http://blog.opensensors.io/blog/2016/09/09/lessons-learned-from-first-generation-iot-installations</id>
    <content type="html"><![CDATA[<p>At first glance,Wi-Fi-based sensors seems like a good choice for a non consumer facing sensor network, however, we have discovered that Wi-Fi has some significant drawbacks.</p>

<h2>Access</h2>

<p>One of the biggest drawbacks to Wi-Fi enabled sensors in a corporate environment at many of the companies is gaining access. Corporate IT often has valid security concerns of hundreds if not thousands of sensors joining the network and have deployed corporate firewalls that block any access.  Often this means that we are not allowed to spin up our own Wi-Fi network in order to have a gateway for a customer’s IoT sensor network. If IT has already deployed a Wi-Fi network they are rarely willing to provide the passwords to allow the IoT network devices and gateways to take advantage of it.  Relying on corporate Wi-Fi can make on-site installations and maintenance extremely complex and painful. The whole project becomes dependent on the goodwill of a network administrator for access every time maintenance needs to be performed.</p>

<h2>Power</h2>

<p>Wi-Fi has good transmission range but that comes with a cost of high power usage. With a short battery life, maintenance costs for Wi-Fi sensors are higher than low-power alternatives. One wireless protocol that is we see in many successful deployments is LoRa because it offers long transmission range at a much lower battery usage than Wi-Fi.</p>

<p>Moving to LoRa and other long range protocols</p>

<p>If you follow our blog and publications, you will notice we have been talking a lot about network technologies, this isn’t a coincidence.  We have spent a long time evaluating and piloting these stacks with our community.</p>

<p> Network access and battery constraints are driving the move to long range networks and off WiFi for many IoT installations. LoRa is working well for us so far for a number of use cases most of our customer spin up a private network.  The ecosystem of providers is maturing and we are finding a lot of companies who are adopting existing sensors for their networks Gateway providers such as <a href="http://www.multitech.com/brands/multiconnect-conduit">Multi Tech</a> provide good support for the long tail of small scale (> 250 sensor installs) hardware providers to thrive.</p>

<p>LoRa is a wireless protocol that promises between two and five kilometers transmission range between sensors and gateway, if you haven&rsquo;t already done so please read our introduction to <a href="http://blog.opensensors.io/blog/2016/07/05/what-is-lorawan/">what it is</a>. With a separate LoRa network, facilities and/or operations can install and manage the whole operation without the access and security issues of using the corporate Wi-Fi network. A typical network will have hundreds of sensor devices sending messages to a gateway. The LoRa gateway is a self contained system, we can have the LoRa network sit completely outside of the corporate firewall (GSM) and minimize IT security concerns.</p>

<p>One LoRA gateway can normally cover an entire real estate. This can significantly reduce infrastructure, deployment, and administration costs compared to other shorter range wireless options like Zigbee or Bluetooth that requires complex installs.  Our aim is to have a system that non technical engineers can roll out and support, more on how to do this on later blog posts, but in most cases the OpenSensors team is the equivalent of &lsquo;2nd line support&rsquo; to the onsite team who have intergrated our apis to their helpdesk ticketing systems etc.</p>

<p>LoRa networks can be public or private. An example of a public network is The Things Network, we continue to work with and support that community.  Most current commercial projects are running private networks at this time but will be interesting to see how that evolves over time.</p>

<p>To conclude, LoRa is working well for us at the moment but we will keep researching other networks to enable us to understand the pros and cons of all the network providers.  Sigfox is a very interesting offering that we will properly test over the next few months, for example.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Savvy Building Managers Use Sensors to Reduce Operating Expenses]]></title>
    <link href="http://blog.opensensors.io/blog/2016/09/08/savy-building-managers-use-sensors-to-reduce-operating-expenses/"/>
    <updated>2016-09-08T18:16:00+01:00</updated>
    <id>http://blog.opensensors.io/blog/2016/09/08/savy-building-managers-use-sensors-to-reduce-operating-expenses</id>
    <content type="html"><![CDATA[<p>Sensor networks are emerging as a mission critical method for offices and commercial spaces to save money. Offices and commercial spaces are undergoing a smart transformation by connecting and linking HVAC, lighting, environmental sensors, security, and safety equipment. Building and facilities managers are also installing utilization sensors to manage their spaces more efficiently.</p>

<p>Main benefits of data driven buildings
* Operational efficiency
* Use data for better design
* Better workspace experience for employees</p>

<h2>Changing workforce</h2>

<p>Recently we helped a company design a prototype of a desk sensor monitoring system. Because so many of their people were working from home they wanted to accurately measure the peak demand during the day to see if they could save 10-20% of their desk space. Goals for the system were:
* Monitor desk occupancy anonymously.
* Minimize installation and deployment costs: rely on solutions that were simple enough that existing non-expert personnel could be trained to deploy.
* Minimize day-to-day maintenance and deployment: this drove strategies for long battery life among others.
* Design a deployment process that ensured install team could easily add sensor location metadata to allow for rich reporting and analysis once IoT sensor network was operational.
* Limit the IT resources needed for deployment</p>

<h2>The  phased approach works best</h2>

<p>First, we looked at many sensors, evaluating quality, signal-to-noise ratio and power consumption. It&rsquo;s always a good idea to get a handful of different types of sensors and try them out in a very small scale. We chose an infrared red sensor with good battery life-time and a single LoRa gateway that could support all the floors and provide connection to the cloud.</p>

<p>Next we did a full end-to-end test, where we hooked up 5-10 sensors up completely to a cloud infrastructure all the way through the connectivity gateway. Now we had real data flowing into the infrastructure and could verify that the queries and analytics were feasible.  This step just makes sure everything works as planned and you will get all the data that you will need.</p>

<p>Once you&rsquo;re happy with the proof of concept phase, it is time for the real pilot phase. Instead of having just a handful of working sensors, now you&rsquo;ll hook up an entire floor or a street or whatever your use case might be. It should be somewhere between thirty, forty, maybe up to a hundred sensors. At this point you can ensure that the sensors work at scale and the gateway can handle the load. Typically we see customers running these for a month or two to get a good feel for how the sensors will perform in a production situation.</p>

<p>After the pilot phase, you should have enough data to verify network performance and your choices for sensors and gateways. Now you can plan the full deployment in detail. It’s been our experience, based on a number of customer installations, that the most successful IoT networks follow these steps in a phased implementation approach.</p>

<p> The technology at the silicon, software, and system level continues to evolve rapidly and our aim is to reduce the time to go live and minimise risk.  The internet of things is a nebulous term that includes quite a lot of specialised skillsets such as sensor manufacturing, network design, data analysis, etc.</p>

<p>In order to make projects successful, we have taken the approach of building many hardware, installation and network provider partnerships, and relationships to help customers succeed as opposed to trying to do it all ourselves.  We have been working with customers to develop methods to lower the sensor density and in turn lower the cost of projects whilst still getting comparable accuracy.</p>

<p>Contact us if you would like assistance on sensor selection, network design, or planning a proof of concept deployment.</p>

<p><img src="http://blog.opensensors.io/images/office.jpg" /></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Getting to Grips With IoT Network Technologies]]></title>
    <link href="http://blog.opensensors.io/blog/2016/07/17/getting-to-grips-with-iot-network/"/>
    <updated>2016-07-17T08:18:00+01:00</updated>
    <id>http://blog.opensensors.io/blog/2016/07/17/getting-to-grips-with-iot-network</id>
    <content type="html"><![CDATA[<p>How sensors communicate with the internet is a fundamental consideration when conceiving of a connected project. There are many different ways to connect your sensors to the web, but how to know which are best for your project?</p>

<p>Having just spent the better part of a week researching these new network technologies, this brief guide outlines the key aspects to focus on for an optimal IoT deployment:</p>

<h2>Advanced radio technology</h2>

<ul>
<li>Deep indoor performance &ndash; networks utilising sub-GHz ISM (industrial-scientific-medical) frequency bands such as LoRaWAN, NWave and Sigfox are able to penetrate the core of large structures and even subsurface deployments.</li>
<li>Location aware networking &ndash; a variety of networks are able to track remote sensors even without the use of embedded GPS modules.
Supporting sensors moving between hubs &ndash; with advanced handoff procedures and innovative network topologies mobile sensors can move around an area and remain in contact with core infrastructure without disrupting data transmission. Intelligent node handoff is also crucial for reducing packet loss, if the connection to one hub is hampered by passing through particularly chatty radiowaves, the node can switch to a better placed hub to relay it&rsquo;s crucial payload.</li>
<li>Interference resistance &ndash; the capability of a network to cleave through radio traffic and interference that would ordinarily risk data loss.</li>
</ul>


<h2>Low energy profiling</h2>

<ul>
<li>Device modes &ndash; LoRaWAN is a great case and point with three classes of edge node: the first, Class A, allows a brief downlink window after each uplink upload i.e after having sent a message, the sensor listens in for new instructions; a Class A node appoints a scheduled downlink slot, the device checks in at a certain point; and the last, Class C type nodes, listen for downlink messages from LoRaWAN hubs at all times. The latter burns considerably more power.</li>
<li>Asynchronous communication &ndash; this enables sensors to communicate data in dribs and drabs where possible, services do not need to wait for eachother thereby reducing power consumption.</li>
<li>Adaptive data rates (ADR) &ndash; depending on the quality of signal and attenuation, modern networks are able to dynamically allocate data rate depending on interference, distance to hub etc. This delivers real scalability benefits, frees up space on the radio spectrum (spectrum optimisation) and improves overall network reliability.</li>
</ul>


<h2>security</h2>

<ul>
<li>Authentication &ndash; maintains data integrity by ensuring the sensor which is publishing that mission critical data really is that sensor and not an impostor node. Ensures information privacy.</li>
<li>End to end encryption (E2E) &ndash; prevents tampering and maintains system integrity.</li>
<li>Integrated security &ndash; good network security avoids potential breaches and doesn&rsquo;t place the onus on costly, heavily encrypted message payloads.</li>
<li>Secure management of security keys &ndash; either written remotely on the initial install or embedded at manufacture, security keys are fundamental to system security. ZigBee&rsquo;s recent security issue shows how not to manage security keys, by sending them unencrypted over-the-air to devices on an initial install.</li>
<li>Receipt acknowledgement &ndash; ensures mission critical data is confirmed received by network or device.</li>
</ul>


<h2>Advanced network design</h2>

<ul>
<li>Full bidirectional comms &ndash; enables over the air (OTA) updates, enabling operators to push new firmware or system updates to thousands of remotely deployed sparse sensors at the push of a button. This is critical to a dynamic and responsive network. As with device modes mentioned previously, bidirectionality allows deployed devices to function as actuators and take action (close a gate, set off a fire alarm etc) rather than just one-way sensors publishing to a server.</li>
<li>Embedded scalability and consistent QoS &ndash; as load increases on a network so too does the capacity of the network. This takes the form of adaptive data rates, prevention of packet loss by interference and channel-blocking, the ability to deploy over-the-air updates and ensuring the capability to add nodes, hubs and maintain existing assets without impacting on overall network service, perhaps through automatic adaptation.</li>
</ul>


<p>There are also a number of legal, cost, market and power focused aspects worth considering that I shall not cover here. But, critically, it&rsquo;s worth mentioning that the majority of these technologies operate on ISM (industrial &ndash; scientific &ndash; medical) frequency bands, and as a result are unlicensed. These bands are  regulated and there are rules, however anyone operating on these bands can do so without purchasing a license. Notably, you don&rsquo;t have sole ownership of a slice of the spectrum, you don&rsquo;t get exclusive access. Therefore, with a variety of other vendors blasting away across the radio waves, these technologies encounter significantly more interference than the licensed spectrum. However, the new networks, LoRa, Sigfox, NWave etc are based on protocols and technologies designed to better sort through this noisy environment, grab a channel and send a message.</p>

<p>Understanding that the airwaves are a chaotic mess  underlines the importance placed on features such as adaptive data rates, node handoff and power saving methods such as asynchronous communication. Wired networks do not have to consider such things. But for most it&rsquo;s not just a case of who shouts loudest wins. The majority of wireless protocols &lsquo;play nice&rsquo; opting for a polite &ldquo;listen, then talk&rdquo; approach, waiting for a free slot in the airwaves before sending their message.</p>

<p>Some protocols such as Sigfox forego such niceties and adopt a shout loud, shout longer approach, broadcasting without listening. A typical LoRaWAN payload takes a fraction of a second to transmit, Sigfox by comparison sends messages 3-4 seconds in length. However, if you just broadcast without listening, Sigfox must therefore operate with severe cycle duty limitations, which translate into a limited number of messages sent per device per day and severe data rate limitations.</p>

<p>These choices also translate into varying costs, and critically, into battery life limitations and gains, the crux of any remote deployment.</p>

<p>See <a href="https://www.opensensors.io/connectivity">this link</a> for a matrix of the major technologies currently vying for network domination.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[What Is LoRaWAN?]]></title>
    <link href="http://blog.opensensors.io/blog/2016/07/05/what-is-lorawan/"/>
    <updated>2016-07-05T20:17:00+01:00</updated>
    <id>http://blog.opensensors.io/blog/2016/07/05/what-is-lorawan</id>
    <content type="html"><![CDATA[<h1>What is LoRaWAN and why is it &ldquo;better&rdquo; than Zigbee?</h1>

<p>Even long-time IoT enthusiasts struggle with the wealth of technologies that are on offer these days. One of the most confusing phenomena for someone who isn’t a RF engineer is the scale and range of LoRaWAN. If you’ve been in the game for a while, you may have used a ZigBee radio module for wireless data transmission in your own projects. ZigBee-compliant modules had become a gold standard for many industrial applications in the 2000s, featuring >10m range (it was said to be 100m, but that was hardly ever achieved), up to hundreds of kbit/second transfer rate (depending on the model and radio band used) and message encryption by default. Over most cheap proprietary RFM22 transceivers, ZigBee also offered an industry standard following the IEEE 802.15.4 specification for mesh networking. This allowed ZigBee devices to forward messages from one to another, extending the effective range of the network. Despite their rich features, ZigBee devices are limited in range and limiting when it comes to their power consumption and the potential use in IoT application. And this is where LoRaWAN comes into play: It’s a Low-Power Wide Area Network (LPWAN) standard promising a reach of tens of kilometres for line-of-sight connections and aiming to provide battery lives of up to ten years. How can this work?</p>

<p>First, let’s contrast short-range radio standards like the ZigBee with the LPWAN standards like LoRaWAN. RFM22, ZigBee and LPWAN all use radio frequencies in the ultra high frequency (UHF) range. Following the ITU 9 classification, these are devices that use a carrier frequency of 300 MHz to 3 GHz. That is, the radio waves have a peak-to-peak distance of 10-100 cm — a tiny proportion of the electromagnetic spectrum. Here, we find television broadcasts, mobile phone communication, 2.4 GHz WiFi, Bluetooth, and various proprietary radio standards. We all know that television broadcasting transmitters have a significant range, but clearly that’s because they can pack some punch behind the signal. There must be another reason that LoRaWAN does better than the other radio standards. The carrier frequency itself can therefore not explain the range of LPWAN standards.</p>

<p>There is all sorts of hardware trickery that can be applied to radio signals. Rather than allowing those electromagnetic waves orientate randomly on their way to the receiver, various polarisation strategies can increase range. A circular-polarised wave that drills itself forward can often more easily penetrate obstacles, whereas linear-polarised signals stay in one plane when progressing towards the receiver, concentrating the signal rather than dispersing it in different directions of the beam. However, these methods require effort and preparation on both the sender and receiver side, and wouldn’t really lend themselves to IoT field deployment…</p>

<p>The secret sauce of LPWAN is the modulation of the signal. Modulation describes how information is encoded in a signal. From radio broadcasting stations you may remember ‘AM’ or ‘FM’, amplitude or frequency modulation. That’s how the carrier signal is changed in order to express certain sounds. AM/FM are analog modulation techniques and digital modulation interprets changes like phase shifts in the signal as binary toggle. LPWAN standards are using a third set of methods, spectrum modulation, all of which get away with very low, noisy input signals. So as the key function of LPWAN chipsets is the demodulation and interpretation of very faint signals, one could think of a LoRaWAN radio as a pimped ZigBee module. That’s crazy, isn’t it? To understand a little more in detail how one of the LPWAN standards works, in the following we are going to focus on LoRaWAN as it is really ‘the network of the people’ and because The Things Network -a world-wide movement of idealists who install and run LoRaWAN gateways- supports our idea of open data.</p>

<p><img src="http://blog.opensensors.io/images/LoRaWAN_figure.png" /></p>

<p>LoRaWAN uses a modulation method called Chirp Spread Spectrum (CSS). Spread spectrum methods contrast narrow band radio as ‘they do not put all of their eggs into the same basket’. Consider a radio station that transmits its frequency-modulated programme with high power at one particular frequency, e.g. 89.9 MHz (the carrier is 89.9 MHz with modulations of about 50 kHz to encode the music). If you get to receive that signal, that’s good, but if there is a concurrent station sending their programme over the same frequency, your favourite station may get jammed. With spread spectrum, the message gets sent over a wide frequency range, but even if that signal is just above background noise, it is difficult to deliberately or accidentally destroy the message in its entirety. The ‘chirp’ refers to a particular technique that continuously increases or decreases the frequency while a particular payload is being sent.</p>

<p>The enormous sensitivity and therefore reach of LoRaWAN end devices and gateways has a price: throughput. While the effective range of LoRaWAN is significantly higher than ZigBee, the transmitted data rate of 0.25 to 12.5 kbit/s (depending on the local frequency standard and so-called spreading factor) is a minute fraction of it &ndash; but, hey, your connected dishwasher doesn’t have to watch Netflix, and a payload of 11-242 bytes (again, depending on your local frequency standard etc) is ample for occasional status updates. Here is where the so-called spreading factor comes into play. If your signal-to-noise ratio is great (close proximity, no concurrent signals, etc), you can send your ‘chirp’ within a small frequency range. If you need to compensate for a bad signal-to-noise ratio, it’s better to stretch that ‘chirp’ over a larger range of frequencies. However, that requires smaller payloads per ‘chirp’ and a drop in data rate.</p>

<p>Power consumption, reach and throughput are all linked. To burst out a narrow transmission consumes more power than to emit a spread signal. Hence, LoRaWAN implements an adaptable data rate that can take into account the signal-to-noise ratio as well as the power status of a device.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Taking the Air at the Turk’s Head]]></title>
    <link href="http://blog.opensensors.io/blog/2015/12/18/taking-the-air-at-the-turks-head/"/>
    <updated>2015-12-18T14:45:00+00:00</updated>
    <id>http://blog.opensensors.io/blog/2015/12/18/taking-the-air-at-the-turks-head</id>
    <content type="html"><![CDATA[<h2>Summary</h2>

<p><img src="http://blog.opensensors.io/images/TurksHead.jpg" /></p>

<p>Opensensors.io are pioneers in open data and the internet of things, surfacing a wide range of data sets for open analysis. As an open data aggregator we deliver content over a common infrastructure; whether air quality or transport data, you only have to think about one integration point. Future cities need low data transaction costs for friction free operation, bridging technical gaps slow progress, so keeping the number of integration points low makes sense everybody.</p>

<p>Our journey starts here, as we build out our opendata content expect to see more stories, more insight and hopefully some catalysts for positive change.</p>

<p>Before our first story, consider what will make open data and the Internet of things useful.</p>

<p>We must bridge the gap from data to information, allow consumers to abstract away the complexity of IoT to ask questions that makes sense to them.</p>

<p>Take data from the <a href="http://www.londonair.org.uk/LondonAir/guide/default.aspx">London Air Quality network (LAQN)</a>, the network is sparse so it&rsquo;s improbable our need maps directly to a sensor. By coupling some simple python code with <a href="https://www.opensensors.io/orgs/london-air-quality-network">opensensors data</a> we’ll mash some LAQN data together to get some insight about air quality in wapping.</p>

<p>In this story i’ll show how we can bridge the information gap with some simple code, yielding valuable insight along the way!</p>

<h2>Chapter 1: Opensensors.io Primer</h2>

<p>First a quick primer on how data is structured in opensensors.io <a href="http://support.opensensors.io/support/solutions/articles/6000025426-opensensors-glossary-of-terms">(for more detail check out our forum and glossary of terms)</a></p>

<ul>
<li>Devices &ndash; Each connected ‘thing’ maps to a secured device, things map one-to-one to a device</li>
<li>Topics &ndash; Data is published by devices to topics, a topic is a URI and is the pointer to a stream of data</li>
<li>Organisations (orgs) &ndash; An organisation owns many topics and is the route of an orgs topic URI</li>
<li>Payloads &ndash; Payloads are the string content of messages sent to topic URI’s, typically JSON</li>
</ul>


<p>Also check out our RESTful and streaming APIs on the <a href="https://api.opensensors.io/index.html">website</a> for more background and online examples.</p>

<h2>Chapter 2: Putting JSON to Work</h2>

<p><img src="http://blog.opensensors.io/images/json-to-work.png" />
You can use the opensensors REST API to gather data for research, but it comes in chunks of JSON which isn’t great for data science. For convenience i wrapped up some common data sources for London into a <a href="https://github.com/troups/AQ">python class</a>. Since IoT data is rarely in a nice columnar form it&rsquo;s valuable to build some simple functions to shape the data into something a bit more useful.</p>

<h2>Chapter 3: Introducing the Turks Head</h2>

<p><img src="http://blog.opensensors.io/images/introturkshead.png" /></p>

<p>I’m fortunate to spend a lot of time in Wapping, in and around the community of the <a href="http://www.turksheadcharity.com/story/">Turk’s Head Workspace and Cafe</a>, but unfortunately we don’t have a local LAQN sensor. With a bit of data science and opensensors.io open data we can estimate what NO2 levels might be around the cafe and workspace.</p>

<p>A simple way to estimate NO2 is a weighted average of all the LAQN sensors, in this case we derive the weights from the distance between the sensor and our location. Since we want to overweight the closest sensors we can use an exponential decay to deflate towards zero for those far away.</p>

<p>For the Turks Head sensors in Aldgate, Southwark and Tower hamlets and the City are the closest and have the biggest impact on our estimate.</p>

<h2>Chapter 4: Getting into the Data</h2>

<p><img src="http://blog.opensensors.io/images/gettingintothedata.png" />
With our air quality time series, and our weights we can dig into what our estimates for the Turks Head look like (NO2 * weight). Here’s the series for NO2 over the last 20 days, it looks like the peaks and troughs repeat, and the falling or rising trend is persistent in between.</p>

<p>Trend followers in finance use moving averages to identify trends, for example the <a href="https://en.wikipedia.org/wiki/MACD">MACD indicator (moving average convergence divergence)</a>. MACD uses the delta between a fast and slow moving average to identify rising or falling trends, we’ll do the same. For our purposes we’ll speed the averages up using a decay of 3 and 6 periods (LAQN data is hourly and we are resampling to give estimates on the hour).</p>

<p>What can we conclude from the charts for The Turks Head? From the left hand chart we can see the data is little noisy,with a flat line showing some missing or ‘stalled’ data. Looking at the 3 and 6 period decayed averages the data is smoother, with the faster average persistently trending ahead of the slower one.</p>

<p>Even with fast moving decays the averages cross only a couple of times a day, showing persistence when in trend. So using a simple trend indicator and the LAQN we can build a simple air barometer for the Turks Head.</p>

<p>Good    3 period exp average &lt;  6 period average (green)
Bad     3 period exp average > 6 period average (red)</p>

<p>This is helpful because, given a persistent trend state, where we have a ‘good’ air now, we’ll probably have ‘good’ air for the following hour.</p>

<h2>Chapter 5: What’s the trend across London?</h2>

<p><img src="http://blog.opensensors.io/images/trends.png" />
So we now have means of defining how NO2 levels at the Turk’s Head are trending, but is the trend state predictable over a 24 hour period?</p>

<p>Remember we define good or bad air quality trend as:</p>

<p>Good    ‘fast’ average  &lt;  ‘slow’ average  = falling NO2
Bad     ‘fast’ average  >  ‘slow’ average  = rising NO2</p>

<p>If we aggregate data into hourly buckets we can visualise how much of the time, over the past 20 days, a sensor has been in a up trend (‘good’) for a given hour.</p>

<p>x = hour of the day
y = percentage of bucket that is in a ‘good’ state</p>

<p>We can see that for each 1 hour bucket (24 in total) there is a city wide pattern; if we aggregate across the city (using the same measure, the percentage of sensors in up or down trend) we get an idea of how NO2 trends over a typical day.</p>

<p>Our right hand chart shows the percentage of ‘good’ versus ‘bad’ NO2 sensor states across London over the past 20 days (collected from about 80 sensors over 20 days)</p>

<p>Now this is a really simple analysis but it suggests the proportion of ‘good’ trends across London is high before 7am, and then falls away dramatically during the morning commute. No surprises there.</p>

<p>But the pattern isn’t symmetrical; after peaking around lunchtime, when only ~20% of the cities sensors having improving NO2, NO2 falls throughout the afternoon. From a behavioural standpoint this makes sense; there is a more concentrated morning commute relative to the evening. Most of us arrive at the workplace between say 8 and 9am, but in the evening we may go to the gym, we may go out for dinner, or just work late. The dispersion of our exits from the city is wider than when we enter.</p>

<h2>Chapter 6 &ndash; PM versus NO2</h2>

<p><img src="http://blog.opensensors.io/images/pmvsno2.png" />
So we have considered NO2 as our core measure, in part because there are more sensors in the LAQN delivering this data than particulates. But let’s consider particulates for a moment, LAQN deliver PM10 and PM2.5 measures, the definition can be found here.</p>

<p>Our temporal curves for particles differ from NO2 taking longer to disperse during the evening rush hour (remember we are measuring percentage of sensors in a ‘good’ state). As a measure of air quality NO2 builds up faster, and decays faster once peak traffic flows have completed, whereas particles linger only fading deep into the night (on average).</p>

<h2>Closing Thoughts</h2>

<p>In our data set, NO2 and PM measures differ in their average behaviour over a typical 24 hour period.</p>

<ul>
<li><p>Behavioural interventions will need to consider whether particulates or N02 are the most impactful.</p></li>
<li><p>How can we communicate air quality to our citizens, and relate their personal needs to the measures most impactful on their lives?</p></li>
<li><p>Do we need additional sensors to create a more dense air quality resource? How can we allocate funds to optimally support network expansion and air quality services?</p></li>
<li><p>Knowing the characteristics of a sensor (location, calibration, situation [elevated, kerb side, A or B road]) will improve estimates, how can we deliver this meta-data?</p></li>
</ul>


<p>Plenty of food for thought…………..information</p>

<h2>Notes and Resources</h2>

<p>Our stories are quick and dirty demonstrators to promote innovation and should be treated as such. All data science and statistics should be used responsibly :)</p>

<p>All of the code supporting this can be found on <a href="https://github.com/troups/AQ">github</a> with data sourced from <a href="https://www.opensensors.io/orgs/london-air-quality-network">opensensors’ LAQN feed</a>, and i use a postcode lookup to get long/lat locations for wapping. I’ve also taken some inspiration from <a href="https://github.com/e-dard/boris">https://github.com/e-dard/boris</a> and <a href="https://github.com/tzano/OpenSensors.io-Py">https://github.com/tzano/OpenSensors.io-Py</a> so thanks for their contribution!</p>

<p><a href="http://www.londonair.org.uk/">http://www.londonair.org.uk/</a>
<a href="https://www.opensensors.io/">https://www.opensensors.io/</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The Path to Smart Buildings]]></title>
    <link href="http://blog.opensensors.io/blog/2015/10/07/the-path-to-smart/"/>
    <updated>2015-10-07T10:14:00+01:00</updated>
    <id>http://blog.opensensors.io/blog/2015/10/07/the-path-to-smart</id>
    <content type="html"><![CDATA[<p>Google <a href="http://lmgtfy.com/?q=principles+of+good+architectural+design#seen">&lsquo;principles of good architectural design&rsquo;</a>  and you’ll get links to technology, to buildings and all manner of other services. But it’s hard to find principles of design for the tech services that facilitate smart buildings. Let’s remind ourselves what a smart building is with the help of <a href="http://sustainabletechnologyforum.com/from-inspired-to-awful-8-definitions-of-smart-buildings_18078.html">sustainable tech forum</a>; ‘The simple answer is that there’s automation involved somehow that makes managing and operating buildings more efficient’. So the need is well documented but we want to bridge to the ‘practice of designing and constructing buildings’, after all that’s what architecture is about.</p>

<p>Opensensors hosted its first Smart Building Exchange (SBeX) event in September, and we are grateful to the panelists and attendees who made it such a success. Our goal was to bridge the gap between widely documented features of smart buildings and the tech that underpins it. Through our workshops we decomposed tenant needs and identified services to support them using the <a href="http://www.businessmodelgeneration.com/canvas/vpc">value proposition canvas</a>. We borrow from lean product design principles since building operators need to rapidly innovate using processes inherited from startups. Mapping the pains and gains of users to the features and products of the tech stack revealed a common theme, data infrastructure. Data is the new commodity that new services will be built upon, some will be open and others private, but data will be the currency of the next generation smart building.</p>

<p><img src="http://blog.opensensors.io/images/sbex-summary.png"/></p>

<p>Take integrated facilities management (IFM) where data serves the desire to deliver better UX at a lower cost with fewer outages. IFM has pivoted from a set of siloed software services to a set of application services overlaid upon a horizontal data infrastructure. For example:</p>

<ul>
<li>Data science services will develop to identify ‘rogue’ devices operating outside expected patterns, they will identify assets that need inspection or replacement and schedule maintenance works using time and cost optimisation routines.</li>
<li>Digital concierge services will use personal devices, location based technology and corporate data (calendar and HR data) to optimise both user experience and spacial allocation.</li>
</ul>


<p>So can we identify a tech architecture to support this pivot from monolithic apps? Data services facilitated by a central messaging backbone allows the complexity of building services to be broken down and tackled one service at a time, lowering the risk failure and allowing agile iterations at a reduced cost. Take the pillars of data driven applications for IFM as identified by our workshop group; predictive/reactive alerting and tactical/strategic reporting, how might we go about servicing these needs? Consider how the path to smart buildings outlined below could help build an IFM product.</p>

<p><img src="http://blog.opensensors.io/images/PathToSmart.png" /></p>

<ul>
<li>Build the value proposition founded on a clear vision of what your users want.</li>
<li>Identify the data that will drive your smart building product including open data</li>
<li>Identify the sensors needed to gather your data, they could be mobile devices or occupancy sensors</li>
<li>Identify connectivity from the sensor to your data infrastructure, this might be radio to IP connected gateways or directly onto the local network via POE (power over ethernet)</li>
<li>Structure your message payloads and commit to schemas to deliver repeatable processes for message parsing and routing within your building</li>
<li>Configure your events turning your data into information using rules based platforms for IoT such as node red</li>
<li>Build widgets and data services that can be bound together for dashboarding. By identifying common user needs across the enterprise we can operate a leaner system stack</li>
<li>Build user portals and dashboards using your common data services and components</li>
<li>Validate tenant user experience through surveys and modelling tenant behaviour using occupancy devices</li>
<li>Iterate to improve using data gathered throughout the building to deliver better products and experiences</li>
</ul>


<p>Opensensors has firmly backed Open Source and Open Data as the best way to yield value from the Internet of Things choosing to collaborate with the tech community to enable facilities managers to build higher order systems focused on their domain expertise.  Please contact <a href="&#109;&#x61;&#105;&#108;&#x74;&#x6f;&#x3a;&#99;&#111;&#109;&#x6d;&#x65;&#114;&#99;&#105;&#97;&#108;&#x74;&#101;&#97;&#109;&#x40;&#111;&#x70;&#101;&#x6e;&#x73;&#101;&#110;&#115;&#111;&#114;&#x73;&#46;&#x69;&#111;">&#99;&#111;&#x6d;&#109;&#101;&#114;&#x63;&#105;&#97;&#108;&#116;&#101;&#x61;&#x6d;&#64;&#x6f;&#112;&#101;&#110;&#115;&#x65;&#110;&#115;&#111;&#114;&#115;&#46;&#105;&#111;</a> should you have a need for a smart building workshop or are ready to build your next generation smart building product.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Don't Make Me Think]]></title>
    <link href="http://blog.opensensors.io/blog/2015/08/24/dont-make-me-think/"/>
    <updated>2015-08-24T13:18:00+01:00</updated>
    <id>http://blog.opensensors.io/blog/2015/08/24/dont-make-me-think</id>
    <content type="html"><![CDATA[<p>Expect the early adopters of ‘enchanted’ buildings to be our employers, the world green building council estimate we spend 10% of our costs on facilities management, 90% is the expense of executing our business. You don’t have to be an accountant to realise a 1% improvement in productivity trumps a 1% saving facilities costs by 9 to 1!  So how might smart buildings deliver productivity and improved user experience (UX)?</p>

<p>Great UX should be pain free,”Don’t make me think” (Steve Krug). Whilst smart phones offer a means of logging in to a workplace, it’s a bind to install the app, to login, to connect and privacy and indoor location services are a challenge. IoT tech such as OpenSensors, beacons, noise and air quality sensors, coupled with responsible anonymisation can deliver on productivity because improved building and personal wellness simply means we get more done. But how might this work?</p>

<p>Aarron Walter said “Designers shooting for usable is like a chef shooting for edible.”, as techies we can apply these ideas to civic interactions. Take a large office space, I arrive from out of town, I’m visiting for a meeting with my project team. I register, head off to the flexible space and grab a desk, perhaps wasting time trying to find my guys. Each of the team then arrive, some may co-locate, others disperse, there’s no convenient breakout space; the collaboration is diluted and we’re disturbing others. We ate but it wasn’t a great meal.</p>

<p>The lack of an inexpensive, robust, secure and open tech stack rendered us powerless, we have been consuming ‘edible’ tenant experiences rather than a delightful meal. But tech is moving fast; expect new digital services enabled by advances in IoT hardware and data software to shake down the industry. Organisations ready to invest and experiment will move ahead, they’ll develop an ‘edge’ that will define their services and branding for years to come.</p>

<p><strong>Digital concierge</strong> &ndash; expect to sign in digitally on a device that will bind you, your calendar, your co-workers and your building. Through data expect intelligent routing to the best work space for your or your groups needs.</p>

<p><strong>Location based services</strong> &ndash; sensors enable ‘just in time’ cleaning services that clear flexible working space when meetings conclude, or sweep loitering coffee cups and deliver fresh coffee during breaks in longer workshops.</p>

<p><strong>Environmental factors</strong> &ndash; expect IoT to bubble up environmental data such as air quality, temperature, humidity, light and noise that can be used to adjust HVAC systems in real time, or to aide interior designers in improving the workplace.</p>

<p><strong>Smart facilities management</strong> &ndash; location based services coupled with smart energy grid technology will allow fine tuning of energy supply reacting to changes in demand and national grid status (smart grid frequency response).</p>

<p><strong>Data science</strong> &ndash; each of the above services a specific need whilst wrangling data sets into an ordered store. Technology like opensensors can then add further value through real time dashboarding for health and safety or real time productivity management. Furthermore, once data is captured we can apply machine learning to deeper understand the interactions of our human resources and physical assets through A/B testing or other data science.</p>

<p>Unlocking great UX in buildings boils down to data; capturing it, wrangling it, applying science and iterating to make things better. First we must gather the data from the systems in place (see First ‘Things’ First) whilst supplementing from new devices such as air quality, occupancy through sensors or beacons. Having provided a robust data fabric tenants need to become active rather than passive, agile rather than rigid in their approach to managing their assets. IoT devices and data services will deliver an edge for delivering the best of breed user experience that tenants value so highly.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Monitoring for Earthquakes With Node-red]]></title>
    <link href="http://blog.opensensors.io/blog/2015/08/14/monitoring-for-earthquakes-with-node-red/"/>
    <updated>2015-08-14T15:07:00+01:00</updated>
    <id>http://blog.opensensors.io/blog/2015/08/14/monitoring-for-earthquakes-with-node-red</id>
    <content type="html"><![CDATA[<p>OpenSensors now capture seismic data from the Euro-Med Seismic Centre (EMSC) and the United States Geological Survey (USGS). Every ten minutes we are polling the latest information of major and minor earthquakes around the globe and make this information available via our programming interface (API) or as MQTT feed.
In this short tutorial, we’re showing you how to use OpenSensors together with Node-RED to receive email alerts whenever there’s a major incident in a region of interest. You can use this guide as starting point for further experiments with Node-RED and develop your own earthquake-triggered workflows. Let’s shake it.</p>

<h2>On OpenSensors</h2>

<ul>
<li><p>First, you need to login to your account on OpenSensor or sign up for one if you haven’t done so already at <a href="https://opensensors.io.">https://opensensors.io.</a></p></li>
<li><p>Next, it’s good practice to have a new ‘device’ for this application, i.e. a dedicated set of credentials you’re going to use to log in to OpenSensors for this particular set of MQTT feeds.</p>

<ul>
<li>In the panel on the left, click My Devices in the Devices menu.</li>
<li>Click the yellow Create New Device button at the top of the page.</li>
<li>Optional: Add some optional descriptions and press the disk icon to save your new device.</li>
<li>Take a note of your ‘Client id’ and ‘Password’ as you’re going to need them in your Node-RED workflow.</li>
</ul>
</li>
</ul>


<p><img src="http://blog.opensensors.io/images/quakelistener.png" /></p>

<h2>For Node-RED</h2>

<p>Install node.js and Node-RED on your system. There’s a very good guide for this on the <a href="http://nodered.org/docs/getting-started/installation.html">Node-RED website</a>. Follow the instructions, including the separate section on Running Node-RED.</p>

<p>Once you’re ready, open a web browser and direct it to localhost:1880, the default address and port of the Node-RED GUI on your system.</p>

<p><img src="http://blog.opensensors.io/images/noderedquake.png" /></p>

<p>(A very basic description of the Node-RED vocabulary can also be found at <a href="http://www.slideshare.net/BorisAdryan/node-red-workflowcoursetoulouse">SlideShare</a>.)</p>

<h2>Developing a workflow</h2>

<ul>
<li><p>From the input panel of your nodes library on the left side, drag and drop a pink mqtt input node into the work area named Sheet  1.</p></li>
<li><p>Double-click the mqtt node. A window with configuration details opens.</p>

<ul>
<li>Click the pen symbol next to ‘Add new mqtt-broker&hellip;’. Your Broker is opensensors.io, your Client ID and Password those you generated in the previous step on the OpenSensors website, and User is your OpenSensor user name.</li>
</ul>
</li>
</ul>


<p><img src="http://blog.opensensors.io/images/noderedmqtt.png" /></p>

<ul>
<li>Once the Broker is defined, enter /orgs/EMSC/+ into the Topic field. This is going to instruct Node-RED to subscribe to all MQTT topics generated by the EMSC.</li>
<li><p>Optional: Set the Name of this node to ‘EMSC’.</p></li>
<li><p>Drag and drop a second mqtt input node. When you double-click the node, you will realise that the Broker settings default to the ones you previously entered.</p>

<ul>
<li>Enter /orgs/USGS/+ in the Topics field and ‘USGS’ as optional Name.</li>
</ul>
</li>
<li><p>Drag and drop a dark green debug node from the output panel on the left. While debugging has the connotation of fixing a problem, in Node-RED it’s the default way of directly communicating messages to the user.</p></li>
<li><p>Draw connection lines (“pipes”) from both mqtt nodes to the debug node.</p></li>
</ul>


<p><img src="http://blog.opensensors.io/images/noderedflow.png" /></p>

<ul>
<li>Press the red Deploy button in the upper right corner. This starts your Node-RED flow. If everything worked, you should see ‘connected’ underneath the mqtt nodes and your debug panel (on the right) should soon produce the following JSON-formatted output if there’s an event (which may take a while!):</li>
</ul>


<p><img src="http://blog.opensensors.io/images/nddebugger.png" /></p>

<p>While it is pleasing to be informed about every time the earth shakes, it soon becomes tedious staring at the debug panel in expectation of an earthquake. Also, you may not be interested in events in remote areas of the world, or exactly in those &ndash; whatever interests you.</p>

<p>We are going to extend our flow with some decision making:</p>

<p>First, we need to parse the information from the EMSC and USGS. For this example, we’re going to be particularly interested in the fields region and magnitude. There are plenty more fields in their records, and you may want to adjust this flow to your needs.</p>

<ul>
<li><p>Drag and drop a pale orange function node from the functions panel into your flow. Connect both mqtt nodes to the input side (the left side) of your function node. Function nodes allow you directly interact with your data using JavaScript.</p></li>
<li><p>Enter the following code (or download the OpenSensors workflow).</p></li>
</ul>


<p><img src="http://blog.opensensors.io/images/nseditor.png" /></p>

<p>Here be a JavaScript course… :&ndash;) In a nutshell, this code takes data from the ‘payload’ of the incoming message (read up on the topic and payload concept of Node-RED in the SlideShare article suggested earlier). The payload is then parsed for the region and magnitude fields using standard regular expressions. If we can successfully extract information (in this case: the region containing ‘ia’ somewhere in it’s name), we’re going to set the outgoing message’s payload to the magnitude, its topic to ‘EVENT in ‘ plus the name of the region and pass it on (‘return msg’) to the next node.</p>

<ul>
<li>Drag and drop a lime green switch node from the function panel into your workflow. Connect the output of the function node to the input of the switch node. Configure (by double-clicking) the switch node to assert if the payload (being the magnitude of the earthquake) is greater than 2. Only then the message is going to be passed on.</li>
</ul>


<p><img src="http://blog.opensensors.io/images/editswitch.png" /></p>

<ul>
<li>Last, we’re going to drag and drop a light green e-mail output node from the social panel and configure it like an e-mail client, but with a default recipient: here in this case, <a href="&#x6d;&#x61;&#105;&#108;&#116;&#111;&#x3a;&#111;&#104;&#109;&#121;&#103;&#111;&#100;&#x69;&#116;&#104;&#97;&#x70;&#x70;&#101;&#110;&#x64;&#x40;&#103;&#109;&#x61;&#105;&#108;&#46;&#99;&#x6f;&#109;&#x2e;">&#111;&#104;&#x6d;&#x79;&#103;&#x6f;&#x64;&#x69;&#x74;&#x68;&#x61;&#x70;&#112;&#101;&#x6e;&#x64;&#x40;&#x67;&#109;&#97;&#105;&#108;&#46;&#x63;&#111;&#x6d;&#46;</a></li>
</ul>


<p><img src="http://blog.opensensors.io/images/nseditemail.png" /></p>

<ul>
<li><p>Connect the output of the switch node to our debug node, as well as to the outgoing e-mail node.</p></li>
<li><p>We can then deploy the new workflow and should see something like this after a while:</p></li>
</ul>


<p><img src="http://blog.opensensors.io/images/newflow.png" /></p>

<p>In this case, an event was detected ‘off the coast of Northern California’ with a magnitude of 4.4 and at the same time, you should receive an e-mail with the region as subject and the magnitude in the body of the e-mail.</p>

<p>We hope that this flow is getting you started! Remember that Node-RED is superbly suited to interact with hardware… &hellip;imagine LEDs and buzzers indicating an earthquake.</p>

<p>The flow JSON:
[{&ldquo;id&rdquo;:&ldquo;e9024ae0.16fdb8&rdquo;,&ldquo;type&rdquo;:&ldquo;mqtt-broker&rdquo;,&ldquo;broker&rdquo;:&ldquo;opensensors.io&rdquo;,&ldquo;port&rdquo;:&ldquo;1883&rdquo;,&ldquo;clientid&rdquo;:&ldquo;1646&rdquo;},{&ldquo;id&rdquo;:&ldquo;2952b879.d6ad48&rdquo;,&ldquo;type&rdquo;:&ldquo;mqtt in&rdquo;,&ldquo;name&rdquo;:&ldquo;EMSC&rdquo;,&ldquo;topic&rdquo;:&ldquo;/orgs/EMSC/+&rdquo;,&ldquo;broker&rdquo;:&ldquo;e9024ae0.16fdb8&rdquo;,&ldquo;x&rdquo;:127,&ldquo;y&rdquo;:104,&ldquo;z&rdquo;:&ldquo;82a1c632.7d5e38&rdquo;,&ldquo;wires&rdquo;:[[&ldquo;490a140f.b6f5ec&rdquo;,&ldquo;163677af.e9c988&rdquo;]]},{&ldquo;id&rdquo;:&ldquo;54239d6.fabdc64&rdquo;,&ldquo;type&rdquo;:&ldquo;mqtt in&rdquo;,&ldquo;name&rdquo;:&ldquo;USGS&rdquo;,&ldquo;topic&rdquo;:&ldquo;/orgs/USGS/+&rdquo;,&ldquo;broker&rdquo;:&ldquo;e9024ae0.16fdb8&rdquo;,&ldquo;x&rdquo;:128,&ldquo;y&rdquo;:159,&ldquo;z&rdquo;:&ldquo;82a1c632.7d5e38&rdquo;,&ldquo;wires&rdquo;:[[&ldquo;490a140f.b6f5ec&rdquo;,&ldquo;163677af.e9c988&rdquo;]]},{&ldquo;id&rdquo;:&ldquo;490a140f.b6f5ec&rdquo;,&ldquo;type&rdquo;:&ldquo;debug&rdquo;,&ldquo;name&rdquo;:&ldquo;&rdquo;,&ldquo;active&rdquo;:true,&ldquo;console&rdquo;:&ldquo;false&rdquo;,&ldquo;complete&rdquo;:&ldquo;false&rdquo;,&ldquo;x&rdquo;:538,&ldquo;y&rdquo;:86,&ldquo;z&rdquo;:&ldquo;82a1c632.7d5e38&rdquo;,&ldquo;wires&rdquo;:[]},{&ldquo;id&rdquo;:&ldquo;163677af.e9c988&rdquo;,&ldquo;type&rdquo;:&ldquo;function&rdquo;,&ldquo;name&rdquo;:&ldquo;parse&rdquo;,&ldquo;func&rdquo;:&ldquo;// uppercase the payload (different centres report in mixed formats)\nmsg.payload = msg.payload.toUpperCase();\n\n// extracting interesting fields with regular expressions,\n// instead of using JSON.parse which fails with null fields\nvar places_with_ia_regex = new RegExp(&#34;REGION&#92;&rdquo;:&#92;&ldquo;(.<em>IA.</em>)&#92;&rdquo;,&#92;&ldquo;UPDATED\&rdquo;);\nvar result1 = places_with_ia_regex.exec(msg.payload);\n\nvar magnitude_regex = new RegExp(\&ldquo;MAGNITUDE&#92;&rdquo;:([0-9].[0-9]+)\&ldquo;);\nvar result2 = magnitude_regex.exec(msg.payload);\n\n// if successful, sets topic to the region and payload to the magnitude\nif (result1 &amp;&amp; result2) {\n  msg.topic = &lsquo;EVENT in &rsquo;+result1[1];\n  msg.payload = result2[1];\n  return msg;\n}&rdquo;,&ldquo;outputs&rdquo;:1,&ldquo;noerr&rdquo;:0,&ldquo;x&rdquo;:296,&ldquo;y&rdquo;:251,&ldquo;z&rdquo;:&ldquo;82a1c632.7d5e38&rdquo;,&ldquo;wires&rdquo;:[[&ldquo;64f4f2ea.9b0b0c&rdquo;]]},{&ldquo;id&rdquo;:&ldquo;64f4f2ea.9b0b0c&rdquo;,&ldquo;type&rdquo;:&ldquo;switch&rdquo;,&ldquo;name&rdquo;:&ldquo;at least magnitude 2&rdquo;,&ldquo;property&rdquo;:&ldquo;payload&rdquo;,&ldquo;rules&rdquo;:[{&ldquo;t&rdquo;:&ldquo;gte&rdquo;,&ldquo;v&rdquo;:&ldquo;2&rdquo;}],&ldquo;checkall&rdquo;:&ldquo;true&rdquo;,&ldquo;outputs&rdquo;:1,&ldquo;x&rdquo;:428,&ldquo;y&rdquo;:179,&ldquo;z&rdquo;:&ldquo;82a1c632.7d5e38&rdquo;,&ldquo;wires&rdquo;:[[&ldquo;490a140f.b6f5ec&rdquo;,&ldquo;f7bcc59c.084338&rdquo;]]},{&ldquo;id&rdquo;:&ldquo;f7bcc59c.084338&rdquo;,&ldquo;type&rdquo;:&ldquo;e-mail&rdquo;,&ldquo;server&rdquo;:&ldquo;smtp.gmail.com&rdquo;,&ldquo;port&rdquo;:&ldquo;465&rdquo;,&ldquo;name&rdquo;:&ldquo;<a href="&#x6d;&#97;&#105;&#108;&#116;&#111;&#x3a;&#111;&#104;&#x6d;&#x79;&#x67;&#111;&#x64;&#x69;&#x74;&#x68;&#x61;&#x70;&#112;&#101;&#110;&#101;&#100;&#x40;&#103;&#x6d;&#97;&#x69;&#108;&#46;&#99;&#111;&#109;">&#111;&#x68;&#109;&#x79;&#x67;&#x6f;&#100;&#105;&#116;&#x68;&#x61;&#x70;&#112;&#101;&#110;&#x65;&#x64;&#64;&#103;&#x6d;&#x61;&#x69;&#108;&#46;&#x63;&#x6f;&#109;</a>&rdquo;,&ldquo;dname&rdquo;:&ldquo;&rdquo;,&ldquo;x&rdquo;:581,&ldquo;y&rdquo;:256,&ldquo;z&rdquo;:&ldquo;82a1c632.7d5e38&rdquo;,&ldquo;wires&rdquo;:[]}]</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[First 'Things' First]]></title>
    <link href="http://blog.opensensors.io/blog/2015/08/06/first-things-first/"/>
    <updated>2015-08-06T16:36:00+01:00</updated>
    <id>http://blog.opensensors.io/blog/2015/08/06/first-things-first</id>
    <content type="html"><![CDATA[<p><img src="http://blog.opensensors.io/images/ODI.jpg" /></p>

<p>I was pleased to see the <a href="http://theodi.org/data-spectrum">recent post</a> by the ODI on the open-shared-closed data spectrum since it resonates with the challenges faced at OpenSensors. To date most of our commercial projects have been at the private end of the spectrum; they are challenging, they are innovative, but they are often not ingesting open data or publishing data as an exhaust.</p>

<p>Are we worried about private IoT messaging? Not too much. Most of our private clients choose to get their own house in order first, after all typically there’s a lot of opportunity to juice existing sensors. First ‘things’ first as they say.</p>

<p>The good news is these deployments are sowing the seeds of sharing behaviours by distributing content internally, releasing data that used to terminate and die. They are unlocking data and distributing for access via API for dashboards, data science and decision support, which is the first step on a journey to openness.</p>

<p>So as a tech company how do we lead our clients and help them deliver open data strategy? We provide the tools to allow organisations to manage data entitlements pushing themselves up the data spectrum to become open. Each of our clients will make their own journey to open up their content, our job is to deliver infrastructure allowing them to manage data at a privacy that works for them.</p>

<p>This is important stuff. IoT tech companies are developing the smart city data network, and we don’t want it to be private.  We want pain free navigation from edge to edge of our urban data grid, whilst feeling secure and confident about the data we consume. Our platforms must secure data whilst facilitating its exchange and entitlement control, so what’s needed to make smart city data exchange a reality? A couple of things spring to mind, we need to &hellip;</p>

<p><strong>Evolve Topics and Communities</strong> &ndash; Expect faster adoption of sharing behaviours within trusted communities. By curating communities with shared interests expect adoption of localised data exchange, say amongst tenants of a commercial property. Communities sharing data should ease the path to universal open data.</p>

<p><strong>Evolve Exchange Mechanisms</strong> &ndash; Transparent pain free data exchange is key to delivering a functionally rich lean IoT data infrastructure, the alternative could be akin to a ‘european data mountain’ of needless and costly sensor deployments.</p>

<p>Building the tech stack for these needs is plenty of work, so as we define the business and technical models for IoT we need to act responsibly. Deploying and decommissioning software is cheap, just a couple of mouse clicks away. IoT deployments are very real, they consume natural resource, risk cluttering our environment and can loiter well past their usefulness.</p>

<p>Encouraging sharing behaviour within IoT through lean shared infrastructure will prevent waste. The alternative would be a legacy of urban junk, we made a mess of space by not decommissioning hardware, lets not do the same with our urban environment and keep it open and centred on communities.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[When Sensors and Open Data Collide]]></title>
    <link href="http://blog.opensensors.io/blog/2015/07/07/when-sensors-and-open-data-collide/"/>
    <updated>2015-07-07T10:23:00+01:00</updated>
    <id>http://blog.opensensors.io/blog/2015/07/07/when-sensors-and-open-data-collide</id>
    <content type="html"><![CDATA[<p>So I’m new to IoT having spent my career trying to find meaning in econometric data (ouch). Given I started life as a structural engineer I’m pretty excited to be working on data products with opensensors.io, feels like I’m back home again. So what’s exciting me today about where IoT and data science collide?</p>

<p>As data scientists we’re always looking at new models, new ways of shaping our view on a given data set to eek out some kind of edge. But at some point it feels like we’re chasing our tails with little hope of finding new factors to make our science better. Without new data, or at least the same data in a more granular or timely form, we’re just rehashing the same functional forms over the same content.</p>

<p>Fortunately life is about to get a whole lot more interesting as more connected devices come on line. We’re experiencing tangible innovation in IoT, we’re not talking hand wavy stuff; at opensensors.io we see hackers, hobbyists and enterprises building the next generation of smart cities with real velocity.</p>

<p>We’re also fired up since we see pretty much everyone embracing openness in their data. Exactly what open data means remains up for debate, but most agree that some flavour of open data is a prerequisite for successful smart cities.</p>

<p>It would be a pretty dumb city where you could only use the data in your own location.  So it makes sense to open pathways for data to be exchanged allowing us all to benefit from advances in technology, without a cost to our built environment. The alternative is a proliferation of street clutter used to deliver data already gathered in our smart buildings. Paradoxically not smart!  Having delivered connected buildings, transport and personal devices can expect a wave of innovation in apps and data science. So what’s would help to make this happen?</p>

<p>Communities &ndash; Architects, hackers and makers provide the crucible of IoT innovation but need support for their creative process. Helping to gong the technical pain points is great, even better is curating communities to support and challenge. Our mission is to build best of breed engineering whilst retaining our community roots leveraging platforms like github and hackster.</p>

<p>Connect existing things – Increasingly we see opensensors.io used to unlock value in existing device estates. For many enterprises it’s the ‘I’ in IoT that is new, to deliver the ‘I’ they need open, available, performant, secure and low cost messaging and data persistence.</p>

<p>Put open data to work – ‘I can’t define it, but I know it when I see it’, to paraphrase Justice Potter Stewart. The debate about what is open data will remain, what is rightly or wrongly tagged as such. But expect innovation in business models firmly founded on principles of open data. ‘Open’ may mean sharing data with your neighbour, your street, your city. Most importantly make it economically attractive for all enterprises to make data available in some form, even if it’s not ‘open’ in the purest sense.</p>

<p>We have an exciting journey ahead delivering significant change to our urban environment. Over a century ago ‘The league of American Wheelman’ catalysed improvements to America’s transport infrastructure; open data movement can deliver similar disruptive change to our urban environment. I hope open data becomes as ubiquitous as our transport network is today; in future no one will recall activists like the ODI and opensensors.io, but that would be a sign of open data’s success.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[HTTP Post]]></title>
    <link href="http://blog.opensensors.io/blog/2015/06/06/http-post/"/>
    <updated>2015-06-06T11:41:00+01:00</updated>
    <id>http://blog.opensensors.io/blog/2015/06/06/http-post</id>
    <content type="html"><![CDATA[<p>Here at OpenSensors we are committed to making it as easy as possible
to get started with your IOT projects. You can now have the ability to
post messages through OpenSensors using HTTP-POST as well as MQTT.</p>

<p>To post a message to a topic simply use this URL:
<a href="https://opensensors.io/topics/TopicID">https://opensensors.io/topics/TopicID</a> and adding the client-id and
password of your device as well as your username in the header</p>

<p>An example command using Curl is:</p>

<pre><code>curl -X POST -H 'client-id: XX' -H 'password: XXXXXXX' -H 'username: yods' https:opensensors.io/topics/users/yods/foo -d '{"value": 1}'
</code></pre>

<p>Next up is support for another great IOT protocol, CoAP!! My policy is
that we will support any open standard and protocol so if there is a
particular protocol you love feel free to send us an <a href="hello@opensensors.io">email</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[You Use Open Data Every Day]]></title>
    <link href="http://blog.opensensors.io/blog/2015/05/17/you-use-open-data-every-day/"/>
    <updated>2015-05-17T13:11:00+01:00</updated>
    <id>http://blog.opensensors.io/blog/2015/05/17/you-use-open-data-every-day</id>
    <content type="html"><![CDATA[<p>You&rsquo;ve done your hair, you&rsquo;ve picked out the perfect outfit and you&rsquo;re set  on making a great first impression. How long have I got? What tube should I get? How soon is the next bus? You check the <a href="http://www.techworld.com/news/startups/londons-citymapper-capitalises-on-decade-of-data-3467301/">CityMapper app</a> &ndash; you find a route and within seconds know exactly how long it will take to get to your hot date. You may not know it, but open data has just made your trip a lot easier.</p>

<p>Transport for London, OpenStreetMaps, Foursquare, Google Maps, Apple Maps and Cyclestreets all provide access to <a href="http://theodi.org/what-is-open-data">open data</a> for others to use. In this case, CityMapper ingests the real-time open data produced by Transport for London, remixes it with freely available open mapping data, adds a touch of their own special sauce, real-time usage and congestion data from CityMapper users, and finally curates this brew in an accessible form for the user, waiting at the bus stop. In short, the CityMapper team takes the available open data, adds value to it and provides that as a service.</p>

<p>It is not an exaggeration to claim the future development of the city is <a href="http://theodi.org/research-afternoons/show-me-the-future-of-the-built-environment-and-open-data">intertwined</a> with open data. From transport data to air quality data to real time high-street footfall, as cities become leaner, genuinely smarter and more efficient the availability of reliable high quality data will become more important than ever. Generating open data from our surroundings is unlocking value and insight from our environment, information that is all around us, for the researcher, for the app developer, for the tinkerer, for the activist.</p>

<p>For cities to succeed in building resilient systems and networks, the emerging data ecosystem in the city can&rsquo;t rely on closed data, closed systems. Devices and sensors in the city won&rsquo;t function as JawBone and FitBit do, two closed devices whose real-time data I couldn&rsquo;t access and share even if I wanted to. Open data is disrupting the digital landscape, former data-as-commodity brokers, such as <a href="http://www.landmark.co.uk/">Landmark</a>, have since fundamentally reshaped the way in which they do business, focusing on curating available data.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How to Make a Battery Last Forever…]]></title>
    <link href="http://blog.opensensors.io/blog/2015/05/12/how-to-make-a-battery-last-forever-dot-dot-dot/"/>
    <updated>2015-05-12T10:42:00+01:00</updated>
    <id>http://blog.opensensors.io/blog/2015/05/12/how-to-make-a-battery-last-forever-dot-dot-dot</id>
    <content type="html"><![CDATA[<p>Many devices in the IoT won’t be mains powered, but require some sort of supply with limited capacity: be it common batteries or rechargeable cells, energy management is a key challenge for the development of IoT products.</p>

<h2>Background</h2>

<p>The basic anatomy of a program on a microcontroller (the little green boards that run the logic of many digital devices) is an infinite loop: as long as you’re powered, do…</p>

<p>Unfortunately, even “doing nothing” costs energy. While a processor is powered, it’s always going to draw some current for the most basic housekeeping. And it’s not just the processor: voltage regulators, interfaces, nearly everything that is connected to a circuit eats up electricity, and most of it is lost in the form of heat.</p>

<p>The data in this section primarily comes from a very good blog post on <a href="http://www.gammon.com.au/power">Power saving techniques for microprocessors</a> by Nick Gammon. Let’s look at an example: Just running an empty loop on the Ardunio Uno (a commonly used microcontroller for hobbyists) draws about 50 mA. That is, with a standard 9V block (supplying 500 mAh), that Arduino can run just about 10 hours from a battery. Clearly not long enough for a hardware product that’s aimed to participate in the IoT.</p>

<p>Processor manufacturers are well aware of this issue and most platforms support a sleep mode. In case of the Arduino Uno, adding just four lines of code reduces the cost of the empty loop to 35 mA. This is still significant, but mostly owed to all the other components on the microcontroller (including a cheerfully blinking light and a wasteful voltage regulator that takes the 9V of the battery and supplies 5V to the board).</p>

<p>Fortunately, ‘real products’ don’t require all the baggage that the Arduino Uno is carrying around. The processor, the Atmel Atmega328, really just draws 0.35 mA in its most optimal sleep mode. If we don’t require particular features of the processor, this can further be reduced to less than 0.5 uA. (Note that this would allow a 500 mAh battery to drive the processor for 10 years – unfortunately, doing absolutely nothing!).</p>

<p>“But IoT devices are supposed to do things!”, I hear you say. Even more so, the hardware to send information into the Internet can be quite energy hungry – remember the times when it was recommended to switch Wifi off while you were on the road with your laptop? Now, many IoT devices, sensors in particular, only need to work in bursts.</p>

<p>Let’s take a look at one of our favourite core components in connected products: <a href="https://www.wirelessthings.net/rf-328-arduino-atmega-328-compatible-radio-transceiver-rfu-328">The RFu328 from Wireless Things</a>. It combines a barebones Atmega328 with a transceiver that can send and receive radio messages to and from an Internet-connected hub device. The processor and the radio can be sent into a deep sleep, drawing 0.5 uA. However, there’s a timer inside the radio that can trigger the Atmega328 chip and wake the entire system, ready to send or receive data at about 30 mA. We may even have to supply electric current to external sensor hardware and increase our need to more than 50 mA for a second, but for our overall energy budget that’s rather marginal – most of the time, our device will be asleep for minutes if not hours.</p>

<h2>Implementation</h2>

<p>For the standard Atmega sleep modes, consult <a href="http://www.gammon.com.au/power">Power saving techniques for microprocessors</a>.</p>

<p>The sleep modes of the RFu328 depend on a simple modification to the hardware as well as a <a href="https://github.com/CisecoPlc/LLAPSerial">library from Wireless Things</a>. In the absence of in-depth documentation, we learned a lot from PCB designs and software examples from the <a href="https://github.com/oxfloodnet">Oxford Flood Network</a>.</p>

<p>In short, the RFu328 can configure the radio to go into the extended sleep mode by sending the ATSM3 AT command. The Wireless Things library handles a lot of the high-level “+++” string handling to communicate with the SRF radio.</p>

<p>Most of the setup magic happens here:</p>

<pre><code>uint8_t setupSRF(char* sleepString) { // set Sleep mode 2
 if (!enterCommandMode()) { // if failed once then try again
 if (!enterCommandMode()) return 1;
 } 
 if (!sendCommand(sleepString)) return 2;
 if (!sendCommand("ATSM3")) return 3;
 if (!sendCommand("ATDN")) return 4;
 return 5;
 }
</code></pre>

<p>and sleepString is a combination of a configuration suffix and the millisecond sleep duration in hexadecimal notation: ATSD1388 – 5 sec; ATSD4E20 – 20 sec; ATSDEA60 – 1 min; ATSD493E0 – 5 min; ATSD1B7740 – 30 min; ATSD36EE80 – 60 min</p>

<p>Everytime the radio wakes up from this sleep, it triggers a pin of the Atmega328, and having</p>

<pre><code>LLAP.sleep(WAKE_PIN, RISING, false); // sleep until woken
</code></pre>

<p>as part of your loop() takes care of listening to that signal.</p>

<h2>Hardware</h2>

<p>So how does the WAKE_PIN (either D2 or D3) get its signal from the SRF? Via a bridge from D11. (A simple wire.) If you have a newer model of the RFu328, there’s a small field labelled ATSM3. This allows you to create a direct solder bridge to D2 or D3 without the need for the wire.</p>

<p>What other hardware modifications may be necessary? Well, most sensors have a quiescent current draw even when they’re not active. Would it not be nice to have them seperated from the battery until they’re really required? That’s exactly what we’re going to do. Transistors can be used to interrupt the flow of current until triggered, and the RFu328 has a sufficient number of pins remaining that allow for controlling (gating) as MOSFET.</p>

<p>An <a href="https://github.com/badryan/arduino/blob/master/ultrasonic_desk_sensor.ino">OpenSensors example</a> on GitHub.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Closing the Loop Between Maker &amp; Customer for Connected Devices]]></title>
    <link href="http://blog.opensensors.io/blog/2015/04/08/closing-the-loop-between-maker-and-customer/"/>
    <updated>2015-04-08T21:49:00+01:00</updated>
    <id>http://blog.opensensors.io/blog/2015/04/08/closing-the-loop-between-maker-and-customer</id>
    <content type="html"><![CDATA[<h2>Onboard IoT hardware as easy as Kindle, at a fraction of the cost.</h2>

<p>Last month we released OpenSensors’ Search and Subscribe features. This IoT Day we’re pushing our latest development, Organisations, or Orgs for short.</p>

<p>Orgs is a new feature focused on streamlining hardware  production workflows and managing large numbers of devices.</p>

<p>With OpenSensors’ Orgs, you are able to manage all of your devices and data in one place with and pretty soon you will get an at-a-glance easy device health monitoring &ndash; giving your customers a seamless user experience equivalent of the Kindle but without Amazon’s budget.  Those of you managing 1000s of devices in the wild are only too aware of how hard it is to manage the workflow between factory and individual devices all over the world.</p>

<p>We’re trying to make IoT onboarding easier for Hardware startups and connected device manufacturers. That’s why we’ve designed a production to customer workflow, think Kindle for IoT.</p>

<p><img src="http://blog.opensensors.io/images/adddevice.png" /></p>

<p>People managing organisations can now batch provision and manage their new devices.  Devices can be searched for and ‘claimed’ by your customers via the UI or API adding relevant meta-data such as location information to help you keep track of your devices and new customers once your connected devices are out in the wild.</p>

<p>It’s an exciting feature, and we hope you’re just as excited as we are.  We want to save you time and effort and also enable you to get your connected devices to market quicker and cheaper.</p>

<p>As some of you may have noticed, we released a stripped down Alpha version of Orgs in our last release. We’ve learned from your feedback.</p>

<p>And we’re not finished yet, we have a lot of plans for Orgs and this is the first step in the journey.  To celebrate IOT day we are giving away 3 months worth of Organisational hosting and functionality to IoT startups.  Get in touch on <a href="&#109;&#97;&#x69;&#108;&#116;&#111;&#58;&#104;&#x65;&#108;&#108;&#x6f;&#x40;&#111;&#x70;&#x65;&#110;&#115;&#101;&#x6e;&#115;&#111;&#x72;&#115;&#x2e;&#105;&#111;">&#104;&#101;&#108;&#x6c;&#111;&#64;&#x6f;&#x70;&#101;&#x6e;&#x73;&#101;&#x6e;&#x73;&#111;&#114;&#115;&#46;&#x69;&#111;</a> for a voucher.</p>

<p>For more details about Organisations and how to use them check out our
<a href="https://opensensors.io/help/">help pages</a></p>

<p>Happy IoT Day!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Resin.io]]></title>
    <link href="http://blog.opensensors.io/blog/2015/04/02/resin/"/>
    <updated>2015-04-02T08:38:00+01:00</updated>
    <id>http://blog.opensensors.io/blog/2015/04/02/resin</id>
    <content type="html"><![CDATA[<p>When you are working with many connected devices updating the software on them can be tedious. Sometimes sensors are in hard to reach locations and having to get to all of them to update a little bit of code can be a nightmare. Resin.io has a solutions for this. They have made it quick and easy to update the code running on all your connected linux devices. This is very useful for Raspberry Pi based sensors.</p>

<p>Here we’ll explain how we used Resin.io to get code running on our devices publishes to our OpenSensors topic.</p>

<h2>Getting Started</h2>

<p>Firstly we checked out the Resin getting started guide found here:</p>

<p><a href="http://docs.resin.io/#/pages/gettingStarted.md">http://docs.resin.io/#/pages/gettingStarted.md</a></p>

<p>We needed to reformat the SD before we got it to boot properly.</p>

<p>Following the instructions on the getting started guide we pushed the node.js text2speech project they suggested. We were surprised at how easy it made getting code running on your PI.</p>

<p>The next step was to push some python code and get it running. We used a barebones hello world python script with the required docker file which we found here:</p>

<p><a href="https://github.com/alexandrosm/hello-python">https://github.com/alexandrosm/hello-python</a></p>

<p>That too was easy to get working.</p>

<h2>Communicating with OpenSensors</h2>

<p>To get the extra packages needed to communicate with OpenSensors we added some lines to the docker file:</p>

<p>RUN apt-get install -y python-pip
RUN pip install paho-mqtt</p>

<p>the -y was needed to select the yes option on the pip install.</p>

<p>Then we added some code that uses the paho-mqtt library in the python script</p>

<p>You can check it out here</p>

<p><a href="https://github.com/louischaman/Resin_HelloOSIO">https://github.com/louischaman/Resin_HelloOSIO</a></p>

<p>You’ll have to change the username and device ID and password to get it working.</p>

<p>It created the image uploaded it and started running without a
hitch. We could see that it was working because the messages were
appearing on the OpenSensors online dashboard for my topic. Resin.io
is a great product that solves a very real problem in a clever way, I
will be adding it to my toolkit.</p>

<p>Does this help you solve a problem you’ve been having with your
connected sensors? If so get contact and let us know what you are up
to on <a href="&#109;&#97;&#105;&#108;&#116;&#111;&#58;&#104;&#x65;&#108;&#108;&#x6f;&#x40;&#111;&#112;&#x65;&#x6e;&#115;&#101;&#110;&#115;&#x6f;&#x72;&#x73;&#x2e;&#105;&#111;">&#x68;&#101;&#108;&#108;&#111;&#64;&#111;&#x70;&#x65;&#110;&#x73;&#x65;&#110;&#x73;&#x6f;&#x72;&#115;&#x2e;&#105;&#x6f;</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Open and Transparent]]></title>
    <link href="http://blog.opensensors.io/blog/2015/03/27/open-and-transparent/"/>
    <updated>2015-03-27T00:18:00+00:00</updated>
    <id>http://blog.opensensors.io/blog/2015/03/27/open-and-transparent</id>
    <content type="html"><![CDATA[<h1>Open And Transparent</h1>

<p>It’s been an interesting few days in OpenSensors HQ. My fairly harmless comment about privacy and security for the Internet of things on Twitter turned into a fracas.  A fairly prominent blogger and activist, Aral Balkan, took issue with our use of the word Open in our company name.  Twitter is not the best medium for nuanced debate so I wanted to address the points raised.</p>

<p>The central point of Aral’s comments can be summed up by his tweet
<em>If you have a closed platform, don’t call it open. Is that too much to ask for?</em></p>

<p>For clarity, here is why we are proud to call ourselves <strong>Open</strong>Sensors.</p>

<h2>Who we are</h2>

<p>We are an Open Data and Internet of Things startup incubated in the
Open Data Institute, founded by our hero Sir Tim Berners Lee.  If you have never come
across open data please check out his
<a href="http://www.ted.com/talks/tim_berners_lee_on_the_next_web?language=en">great talk</a>
about what it is and also see the great <a href="https://okfn.org/opendata/">Open Knowledge Foundation&rsquo;s write up</a>.</p>

<p>The <a href="http://en.wikipedia.org/wiki/Internet_of_Things">Internet of Things (IoT)</a> is a very broad term for
connecting day to day objects and sensors to the internet. In the IoT world open refers to Open Source Software (OSS), Open Data, Open Hardware, Open Protocols and the Open Web. The common thread that holds these ideals together is that accessibility is key to creating value and benefit.</p>

<p>We strongly believe in all of these ideals. We write open source code and we develop firmware for Open Hardware devices and our guiding principle is to support Open Internet of Things and Web protocols.</p>

<p>OpenSensors aims to create a real time public data exchange.  Most public sensor data sets are currently sitting in silos and we will make them available for reuse by anyone with Open Data Licences. Publishers of data sets include individuals, cities, etc  Data such as Air Quality information, flooding, parking etc is so much more useful when it’s accessible and reusable by as many people and services as possible.</p>

<p>In order to do this, we have built a hugely scalable core, thanks to existing Open Source projects.  We use standard web technologies such as HTTP as well as Server Sent Events for easy real time transfer of data between sensors and the web. In addition, we use Open Sensor protocols such as MQTT to enable M2M applications and we will soon have support for another great open protocol CoAP.</p>

<h2>Will all our code be Open?</h2>

<p>We will develop open source software (including our core azondi). We
will also contribute back in some way to the huge amount of open source software we use such as Cassandra, Elastic Search, Postgres,
Netty, a ton of <a href="http://clojurewerkz.org/">clojurewerkz projects</a> and
have incubated <a href="https://github.com/juxt/cylon">Cylon</a>, a security
library, from Alpha.  We have plans to release a ton of other OSS
projects for things that we needed to scratch our itch.  We recognise
that we stand on shoulders of the giants of the computer science world.</p>

<p>All that being said please be aware that we are not a social
enterprise and there will be parts of our code base that will be
private. We are ultimately a for profit company and our aim is to
create a sustainable business model for an engineering led business to
thrive.</p>

<ul>
<li>We want to hire amazing developers to solve hard problems, enable them to unleash their creative energies and love the product.</li>
<li>We pay everyone from interns upwards a sustainable wage.</li>
<li>We value diversity and spend time and money organising community groups for free to give back.</li>
<li>We do not charge to speak at or to arrange community events.</li>
<li>We run paid training events where at least 30% of attendees places
will fully or in part covered by Open Sensors for those that don&rsquo;t have the means to pay the full price.</li>
<li>We do not depend on government funding and our pricing structure is very clear <a href="https://opensensors.io/pricing.">https://opensensors.io/pricing.</a></li>
</ul>


<p>We have a freemium model around open data that will hopefully create a
lot of value to a lot of people.  We also will enable our paid clients to build connected products for a charge in order to pay for servers, salaries, office costs, etc.</p>

<p>We aim to find enough people to give us their hard earned money by building an amazing product. It is that simple. We do not resell private data or try to create revenue from insight into private user behavior.</p>

<h2>Do we have the right to call ourselves Open and claim a seat at the table?</h2>

<p><strong>Hell Yes!</strong> No one gets to play at un-appointed gatekeeper in <strong>our</strong>
communities especially using exclusionary language and labels, not even
the founder of the web and open data.</p>

<p><img src="http://blog.opensensors.io/images/finished.gif" /></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[European Parliament Approves eCall Technology]]></title>
    <link href="http://blog.opensensors.io/blog/2015/03/17/european-parliament-approves-ecall-technology/"/>
    <updated>2015-03-17T10:57:00+00:00</updated>
    <id>http://blog.opensensors.io/blog/2015/03/17/european-parliament-approves-ecall-technology</id>
    <content type="html"><![CDATA[<p><img src="http://blog.opensensors.io/images/autobahn.jpg" /></p>

<p>European Parliament approves eCall connected car platform</p>

<p>The Internet of Things threatens to revolutionise everyday life, embedding and imbuing everyday objects and the world around us with sensors, software and electronics. Through machine-to-machine communication, automation and advanced analytics, we are able to understand and scrutinise our environment and the processes which surround us in ways never conceived. From high level analysis allowing automated condition monitoring of critical engine parts, giving engineers the tools to reduce costly operational downtime to embedding real-time sensors in bridges to predict stresses and flooding. Beyond the Cloud, the Internet of Things brings the internet to the everyday, and there are clear use cases for such technologies in the realm of road safety.</p>

<p>This is where eCall comes in. eCall is a European Commission initiative coming into force on 31 March 2018, making mandatory the deployment of internet-connected sensors into cars that enable emergency services to be immediately contacted and requested automatically after a serious road incident within the European Union. EC VP for Digital, Neelie Kroes, argues “EU-wide eCall is a big step forward for road safety. When you need emergency support it&rsquo;s much better to be connected than to be alone.” eCall will drastically cut European emergency service response times, even in cases where passengers are unable to speak through injury, by sending a Minimum Set of Data (MSD), including the exact location of the crash site.</p>

<p>The deployment of eCall is one of most ambitious EU-wide programs since the 2007 enlargement, rolling out implementation of the eCall platform to some 230 million cars and 33 million trucks in the European Union. Implementation of eCall at a European level (including Norway, Switzerland etc) however benefits consumers and industry through reducing costs due to economies of scale, reducing the installation cost to as little as €100. The basic pan-European eCall service will be free at the point of use for equipped vehicles. It is likely that the eCall technology platform (i.e., positioning, processing and communication modules) will be exploited commercially too, for stolen vehicle tracking, dynamic insurance schemes, eTolling and emerging forms of vehicle-to-vehicle (V2V) and vehicle-to-infrastructure (V2I) road safety systems. eCall will be based upon a standardised platform, one system for the entirety of Europe, aimed at enabling both car and telecoms industries a quick roll out and to avoid crippling OEM versioning and patching <a href="https://www.ftc.gov/news-events/blogs/techftc/2015/02/whats-security-shelf-life-iot?page=1">issues</a>.</p>

<p>In terms of privacy, the basic eCall system has been given the green light by the European Commission on the express condition that <a href="http://ec.europa.eu/information_society/newsroom/cf/dae/document.cfm?doc_id=5963">firm data protection safeguards</a> are in place and that the sensor-equipped vehicles will not push data to external servers except in the case of a crash, or by the actions of the driver, in order to contact the PSAP (Public Safety Answering Point) and will lie dormant until that point. The data transmitted to the emergency services, described as MSD, Minimum Set of Data, are those strictly needed by the emergency services to handle the emergency situation. While in normal operation mode the system is not registered to any telecoms network and no mediating parties have access to the MSD that is transmitted to the PSAPs.</p>

<p>Today the European Parliament&rsquo;s Internal Market and Consumer Protection Committee MEPs <a href="http://www.europarl.europa.eu/news/en/news-room/content/20150316IPR34756/html/Internal-market-MEPs-green-light-life-saving-emergency-call-system-for-cars">voted on and approved eCall</a> pushing forward a life-saving Internet of Things technology that will significantly improve European road safety. The UK Government however, has not followed suit, whilst welcoming the implementation in other member states, feels that &ldquo;it is not cost-effective &hellip; given the increasing responsiveness of our road network, we feel that smart motorways do the same thing,&rdquo; <a href="http://telematicsnews.info/2015/03/12/uk-minister-says-ecall-would-cost-370-million_m6123/?utm_source=twitterfeed&amp;utm_medium=twitter">remarked Minister Perry</a> on behalf of the Department of Transport. Whilst it can be argued that &lsquo;Smart Motorways&rsquo; are far from a worthy substitute to connected cars &amp; V2V/V2I systems, the UK&rsquo;s criticism belies a certain caution with regards to green-lighting <a href="http://www.independent.co.uk/life-style/health-and-families/health-news/nhs-pulls-the-plug-on-its-11bn-it-system-2330906.html">large and costly IT projects</a>. Only time will tell whether the UK Govt&rsquo;s decision has left those drivers not on Britain&rsquo;s Smart Motorways in the lurch.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Measuring Air Quality on Opensensors]]></title>
    <link href="http://blog.opensensors.io/blog/2015/02/22/measuring-air-quality-on-opensensors/"/>
    <updated>2015-02-22T22:22:00+00:00</updated>
    <id>http://blog.opensensors.io/blog/2015/02/22/measuring-air-quality-on-opensensors</id>
    <content type="html"><![CDATA[<h3><strong>Measuring the air quality of the ODI using an Arduino and a Shinyei PPD-42</strong></h3>

<p>So, whilst thinking of a good demonstration for the Opensensors platform, we thought why not see how polluted our workplace is by hooking up a sensor to publish a continuous data stream to the Opensensors messaging broker.<br/>
For this we need an easy to pick up and use sensor,  we settled on the Shinyei PPD-42. We&rsquo;ll use this in order to measure the number of potentially hazardous small particulates in the air, with an arduino connected to a linux PC (or Raspberry PI).</p>

<p>To run this mini-project you will need:</p>

<ol>
<li>Shinyei PPD-42</li>
<li>Arduino UNO</li>
<li>Computer with Linux installed (you can use a Raspberry PI)</li>
</ol>


<p>We are basing this run-through on a project called DustDuino that uses the Shinyei PPD-42 sensor with an arduino and a wifi module. Check it out <a href="http://www.mentalmunition.com/2013/10/measure-air-pollution-in-your-home-or.html">here</a>. We used this project as our reference when setting up the sensor and writing the Arduino code.</p>

<p><img src="http://blog.opensensors.io/images/pic6.jpg" /></p>

<p>Firstly we follow step 2 of the instructions for hooking up the sensor to the Arduino.
Then we download the code from the projects <a href="https://github.com/NodeJournalism/DustDuino">github repository</a> by opening the link for the code DustDuinoSerial.ino selecting raw and saving that page.</p>

<p><img src="http://blog.opensensors.io/images/pic1.png" /></p>

<p>Opening this up in the arduino IDE, we now upload it to our Arduino UNO by connecting the Arduino and pressing upload.</p>

<p><img src="http://blog.opensensors.io/images/pic2.png" /></p>

<p>You can check the data is coming in by using the Arduino IDE’s serial monitor.</p>

<p><img src="http://blog.opensensors.io/images/pic3.png" /></p>

<p>We then need to figure out how to send the incoming serial message to the Opensensors message broker.</p>

<p>To do this we chose to write a Python script. We used the <a href="https://pypi.python.org/pypi/paho-mqtt">Mosquitto Python module</a>.
I’m going to assume that you already have Python installed, as it comes pre-packaged on most versions of Linux.
If you don’t have it already, you&rsquo;ll need to install pip to download and set up the Mosquitto python module. On Ubuntu or Debian this can be done with the following command:</p>

<pre><code>sudo apt-get install python-pip
</code></pre>

<p>Once pip is installed we can install the Mosquitto python client module using the following command:</p>

<pre><code>sudo pip install paho-mqtt
</code></pre>

<p>You can find out how to use the python module by having a read through the website which we’ve linked above.
Writing and compiling python is really easy.</p>

<h3>Hello Python World</h3>

<p>Open up your favorite plaintext editor. Enter the line:</p>

<pre><code>print “Hello World”
</code></pre>

<p>Save it as hi.py. Then in terminal, navigate to your document and enter the command:</p>

<pre><code>python hi.py
</code></pre>

<p>You should see your “Hello World” response. It’s that easy.</p>

<h3>Hello Opensensors</h3>

<p>To use the Mosquitto client python module we can run the following code to test out publishing. You’ll need to replace my username “Louis” (keeping the speech marks), and password with your details:</p>

<p>The mosquitto library we need to communicate with the Opensensors message broker:</p>

<pre><code>import paho.mqtt.client as mqtt
</code></pre>

<p>Initialise the client option with our client ID of our device:</p>

<pre><code>mqttc = mqtt.Client(client_id="939")
</code></pre>

<p>Set our username and password:</p>

<pre><code>mqttc.username_pw_set("Louis", password="AbcDEFgH")
</code></pre>

<p>Connect to the Opensensors server:</p>

<pre><code>mqttc.connect("opensensors.io")
</code></pre>

<p>Publish a message to say hello:</p>

<pre><code>mqttc.publish("/users/Louis/test2", payload="Hello Opensensors!", qos=0, retain=False)
</code></pre>

<p>Disconnect:</p>

<pre><code>mqttc.disconnect();
</code></pre>

<p>Success, you should now have a functioning sensor :)</p>

<p><img src="http://blog.opensensors.io/images/pic4.png" /></p>

<p>Next we need to get the serial working. To find out what your arduino serial port looks like we executed  following command into terminal:</p>

<pre><code>dmesg | grep tty
</code></pre>

<p>The output was something like this&hellip;</p>

<pre><code>[    0.000000] console [tty0] enabled
[ 3522.192687] cdc_acm 7-1:1.0: ttyACM0: USB ACM device
</code></pre>

<p>The second line has details of our Ardiuno. The ttyACM0 is the device name and ‘/dev/ttyACM0’ is the serial port.</p>

<p>To open and read the serial port Python makes it really easy. You can run a little test to check whether it is working by using the following code:</p>

<p>For communication with the Arduino we need to use the serial library:</p>

<pre><code>import serial
ser = serial.Serial(‘/dev/ttyACM0’) # open first serial port
while True:
print ser.readline()        # prints each line it reads from serial
</code></pre>

<p><img src="http://blog.opensensors.io/images/pic5.jpg" /></p>

<p>Finally we just need to hack together the two pieces. Here is the code we used:</p>

<pre><code>import serial
import paho.mqtt.client as mqtt
import time

mqttc = mqtt.Client(client_id="939")
mqttc.username_pw_set("Louis", password="AbcDEFgH")
mqttc.connect("opensensors.io")

ser = serial.Serial('/dev/ttyACM0')  # open first serial port
while True:
message= ser.readline()
print message
mqttc.publish("/users/Louis/ODI/airquality", payload=message, qos=0, retain=False)
time.sleep(1);
</code></pre>

<p>Running this we were publishing our sensor data to Opensensors!</p>

<p>WE recommend adjusting the Arduino code to output the data in JSON format. This will make it easier to read and add functionality.</p>

<p>You can check out the topic producing Open Data we created <a href="https://opensensors.io/topics/users/Louis/ODI/airquality">here</a>!</p>
]]></content>
  </entry>
  
</feed>
