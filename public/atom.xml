<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[OpenSensors.IO]]></title>
  <link href="http://blog.opensensors.io/atom.xml" rel="self"/>
  <link href="http://blog.opensensors.io/"/>
  <updated>2015-08-14T15:37:32+01:00</updated>
  <id>http://blog.opensensors.io/</id>
  <author>
    <name><![CDATA[OpenSensors.IO]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Monitoring for Earthquakes With Node-red]]></title>
    <link href="http://blog.opensensors.io/blog/2015/08/14/monitoring-for-earthquakes-with-node-red/"/>
    <updated>2015-08-14T15:07:00+01:00</updated>
    <id>http://blog.opensensors.io/blog/2015/08/14/monitoring-for-earthquakes-with-node-red</id>
    <content type="html"><![CDATA[<p>OpenSensors now capture seismic data from the Euro-Med Seismic Centre (EMSC) and the United States Geological Survey (USGS). Every ten minutes we are polling the latest information of major and minor earthquakes around the globe and make this information available via our programming interface (API) or as MQTT feed.
In this short tutorial, we’re showing you how to use OpenSensors together with Node-RED to receive email alerts whenever there’s a major incident in a region of interest. You can use this guide as starting point for further experiments with Node-RED and develop your own earthquake-triggered workflows. Let’s shake it.</p>

<h2>On OpenSensors</h2>

<ul>
<li><p>First, you need to login to your account on OpenSensor or sign up for one if you haven’t done so already at <a href="https://opensensors.io.">https://opensensors.io.</a></p></li>
<li><p>Next, it’s good practice to have a new ‘device’ for this application, i.e. a dedicated set of credentials you’re going to use to log in to OpenSensors for this particular set of MQTT feeds.</p>

<ul>
<li>In the panel on the left, click My Devices in the Devices menu.</li>
<li>Click the yellow Create New Device button at the top of the page.</li>
<li>Optional: Add some optional descriptions and press the disk icon to save your new device.</li>
<li>Take a note of your ‘Client id’ and ‘Password’ as you’re going to need them in your Node-RED workflow.</li>
</ul>
</li>
</ul>


<p><img src="http://blog.opensensors.io/images/quakelistener.png" /></p>

<h2>For Node-RED</h2>

<p>Install node.js and Node-RED on your system. There’s a very good guide for this on the <a href="http://nodered.org/docs/getting-started/installation.html">Node-RED website</a>. Follow the instructions, including the separate section on Running Node-RED.</p>

<p>Once you’re ready, open a web browser and direct it to localhost:1880, the default address and port of the Node-RED GUI on your system.</p>

<p><img src="http://blog.opensensors.io/images/noderedquake.png" /></p>

<p>(A very basic description of the Node-RED vocabulary can also be found at <a href="http://www.slideshare.net/BorisAdryan/node-red-workflowcoursetoulouse">SlideShare</a>.</p>

<h2>Developing a workflow</h2>

<ul>
<li><p>From the input panel of your nodes library on the left side, drag and drop a pink mqtt input node into the work area named Sheet  1.</p></li>
<li><p>Double-click the mqtt node. A window with configuration details opens.</p>

<ul>
<li>Click the pen symbol next to ‘Add new mqtt-broker&hellip;’. Your Broker is opensensors.io, your Client ID and Password those you generated in the previous step on the OpenSensors website, and User is your OpenSensor user name.</li>
</ul>
</li>
</ul>


<p><img src="http://blog.opensensors.io/images/noderedmqtt.png" /></p>

<pre><code>- Once the Broker is defined, enter /orgs/EMSC/+ into the Topic field. This is going to instruct Node-RED to subscribe to all MQTT topics generated by the EMSC.    
- Optional: Set the Name of this node to ‘EMSC’.
</code></pre>

<ul>
<li><p>Drag and drop a second mqtt input node. When you double-click the node, you will realise that the Broker settings default to the ones you previously entered.</p>

<ul>
<li>Enter /orgs/USGS/+ in the Topics field and ‘USGS’ as optional Name.</li>
</ul>
</li>
<li><p>Drag and drop a dark green debug node from the output panel on the left. While debugging has the connotation of fixing a problem, in Node-RED it’s the default way of directly communicating messages to the user.</p></li>
<li><p>Draw connection lines (“pipes”) from both mqtt nodes to the debug node.</p></li>
</ul>


<p><img src="http://blog.opensensors.io/images/noderedflow.png" /></p>

<ul>
<li>Press the red Deploy button in the upper right corner. This starts your Node-RED flow. If everything worked, you should see ‘connected’ underneath the mqtt nodes and your debug panel (on the right) should soon produce the following JSON-formatted output if there’s an event (which may take a while!):</li>
</ul>


<p><img src="http://blog.opensensors.io/images/nddebugger.png" /></p>

<p>While it is pleasing to be informed about every time the earth shakes, it soon becomes tedious staring at the debug panel in expectation of an earthquake. Also, you may not be interested in events in remote areas of the world, or exactly in those &ndash; whatever interests you.</p>

<p>We are going to extend our flow with some decision making:</p>

<p>First, we need to parse the information from the EMSC and USGS. For this example, we’re going to be particularly interested in the fields region and magnitude. There are plenty more fields in their records, and you may want to adjust this flow to your needs.</p>

<ul>
<li><p>Drag and drop a pale orange function node from the functions panel into your flow. Connect both mqtt nodes to the input side (the left side) of your function node. Function nodes allow you directly interact with your data using JavaScript.</p></li>
<li><p>Enter the following code (or download the OpenSensors workflow).</p></li>
</ul>


<p><img src="http://blog.opensensors.io/images/nseditor.png" /></p>

<p>Here be a JavaScript course… :&ndash;) In a nutshell, this code takes data from the ‘payload’ of the incoming message (read up on the topic and payload concept of Node-RED in the SlideShare article suggested earlier). The payload is then parsed for the region and magnitude fields using standard regular expressions. If we can successfully extract information (in this case: the region containing ‘ia’ somewhere in it’s name), we’re going to set the outgoing message’s payload to the magnitude, its topic to ‘EVENT in ‘ plus the name of the region and pass it on (‘return msg’) to the next node.</p>

<ul>
<li>Drag and drop a lime green switch node from the function panel into your workflow. Connect the output of the function node to the input of the switch node. Configure (by double-clicking) the switch node to assert if the payload (being the magnitude of the earthquake) is greater than 2. Only then the message is going to be passed on.</li>
</ul>


<p><img src="http://blog.opensensors.io/images/editswitch.png" /></p>

<ul>
<li>Last, we’re going to drag and drop a light green e-mail output node from the social panel and configure it like an e-mail client, but with a default recipient: here in this case, <a href="&#x6d;&#x61;&#105;&#x6c;&#x74;&#x6f;&#58;&#111;&#104;&#109;&#x79;&#103;&#x6f;&#100;&#x69;&#x74;&#x68;&#x61;&#x70;&#x70;&#x65;&#110;&#x64;&#64;&#x67;&#109;&#x61;&#105;&#108;&#x2e;&#x63;&#111;&#109;&#x2e;">&#x6f;&#x68;&#109;&#x79;&#x67;&#x6f;&#x64;&#105;&#x74;&#104;&#97;&#112;&#x70;&#x65;&#110;&#100;&#x40;&#x67;&#109;&#97;&#105;&#x6c;&#46;&#x63;&#111;&#x6d;&#46;</a></li>
</ul>


<p><img src="http://blog.opensensors.io/images/nseditemail.png" /></p>

<ul>
<li><p>Connect the output of the switch node to our debug node, as well as to the outgoing e-mail node.</p></li>
<li><p>We can then deploy the new workflow and should see something like this after a while:</p></li>
</ul>


<p><img src="http://blog.opensensors.io/images/newflow.png" /></p>

<p>In this case, an event was detected ‘off the coast of Northern California’ with a magnitude of 4.4 and at the same time, you should receive an e-mail with the region as subject and the magnitude in the body of the e-mail.</p>

<p>We hope that this flow is getting you started! Remember that Node-RED is superbly suited to interact with hardware… &hellip;imagine LEDs and buzzers indicating an earthquake.</p>

<p>The flow JSON:
[{&ldquo;id&rdquo;:&ldquo;e9024ae0.16fdb8&rdquo;,&ldquo;type&rdquo;:&ldquo;mqtt-broker&rdquo;,&ldquo;broker&rdquo;:&ldquo;opensensors.io&rdquo;,&ldquo;port&rdquo;:&ldquo;1883&rdquo;,&ldquo;clientid&rdquo;:&ldquo;1646&rdquo;},{&ldquo;id&rdquo;:&ldquo;2952b879.d6ad48&rdquo;,&ldquo;type&rdquo;:&ldquo;mqtt in&rdquo;,&ldquo;name&rdquo;:&ldquo;EMSC&rdquo;,&ldquo;topic&rdquo;:&ldquo;/orgs/EMSC/+&rdquo;,&ldquo;broker&rdquo;:&ldquo;e9024ae0.16fdb8&rdquo;,&ldquo;x&rdquo;:127,&ldquo;y&rdquo;:104,&ldquo;z&rdquo;:&ldquo;82a1c632.7d5e38&rdquo;,&ldquo;wires&rdquo;:[[&ldquo;490a140f.b6f5ec&rdquo;,&ldquo;163677af.e9c988&rdquo;]]},{&ldquo;id&rdquo;:&ldquo;54239d6.fabdc64&rdquo;,&ldquo;type&rdquo;:&ldquo;mqtt in&rdquo;,&ldquo;name&rdquo;:&ldquo;USGS&rdquo;,&ldquo;topic&rdquo;:&ldquo;/orgs/USGS/+&rdquo;,&ldquo;broker&rdquo;:&ldquo;e9024ae0.16fdb8&rdquo;,&ldquo;x&rdquo;:128,&ldquo;y&rdquo;:159,&ldquo;z&rdquo;:&ldquo;82a1c632.7d5e38&rdquo;,&ldquo;wires&rdquo;:[[&ldquo;490a140f.b6f5ec&rdquo;,&ldquo;163677af.e9c988&rdquo;]]},{&ldquo;id&rdquo;:&ldquo;490a140f.b6f5ec&rdquo;,&ldquo;type&rdquo;:&ldquo;debug&rdquo;,&ldquo;name&rdquo;:&ldquo;&rdquo;,&ldquo;active&rdquo;:true,&ldquo;console&rdquo;:&ldquo;false&rdquo;,&ldquo;complete&rdquo;:&ldquo;false&rdquo;,&ldquo;x&rdquo;:538,&ldquo;y&rdquo;:86,&ldquo;z&rdquo;:&ldquo;82a1c632.7d5e38&rdquo;,&ldquo;wires&rdquo;:[]},{&ldquo;id&rdquo;:&ldquo;163677af.e9c988&rdquo;,&ldquo;type&rdquo;:&ldquo;function&rdquo;,&ldquo;name&rdquo;:&ldquo;parse&rdquo;,&ldquo;func&rdquo;:&ldquo;// uppercase the payload (different centres report in mixed formats)\nmsg.payload = msg.payload.toUpperCase();\n\n// extracting interesting fields with regular expressions,\n// instead of using JSON.parse which fails with null fields\nvar places_with_ia_regex = new RegExp(&#34;REGION&#92;&rdquo;:&#92;&ldquo;(.<em>IA.</em>)&#92;&rdquo;,&#92;&ldquo;UPDATED\&rdquo;);\nvar result1 = places_with_ia_regex.exec(msg.payload);\n\nvar magnitude_regex = new RegExp(\&ldquo;MAGNITUDE&#92;&rdquo;:([0-9].[0-9]+)\&ldquo;);\nvar result2 = magnitude_regex.exec(msg.payload);\n\n// if successful, sets topic to the region and payload to the magnitude\nif (result1 &amp;&amp; result2) {\n  msg.topic = &lsquo;EVENT in &rsquo;+result1[1];\n  msg.payload = result2[1];\n  return msg;\n}&rdquo;,&ldquo;outputs&rdquo;:1,&ldquo;noerr&rdquo;:0,&ldquo;x&rdquo;:296,&ldquo;y&rdquo;:251,&ldquo;z&rdquo;:&ldquo;82a1c632.7d5e38&rdquo;,&ldquo;wires&rdquo;:[[&ldquo;64f4f2ea.9b0b0c&rdquo;]]},{&ldquo;id&rdquo;:&ldquo;64f4f2ea.9b0b0c&rdquo;,&ldquo;type&rdquo;:&ldquo;switch&rdquo;,&ldquo;name&rdquo;:&ldquo;at least magnitude 2&rdquo;,&ldquo;property&rdquo;:&ldquo;payload&rdquo;,&ldquo;rules&rdquo;:[{&ldquo;t&rdquo;:&ldquo;gte&rdquo;,&ldquo;v&rdquo;:&ldquo;2&rdquo;}],&ldquo;checkall&rdquo;:&ldquo;true&rdquo;,&ldquo;outputs&rdquo;:1,&ldquo;x&rdquo;:428,&ldquo;y&rdquo;:179,&ldquo;z&rdquo;:&ldquo;82a1c632.7d5e38&rdquo;,&ldquo;wires&rdquo;:[[&ldquo;490a140f.b6f5ec&rdquo;,&ldquo;f7bcc59c.084338&rdquo;]]},{&ldquo;id&rdquo;:&ldquo;f7bcc59c.084338&rdquo;,&ldquo;type&rdquo;:&ldquo;e-mail&rdquo;,&ldquo;server&rdquo;:&ldquo;smtp.gmail.com&rdquo;,&ldquo;port&rdquo;:&ldquo;465&rdquo;,&ldquo;name&rdquo;:&ldquo;<a href="&#x6d;&#x61;&#105;&#x6c;&#116;&#x6f;&#x3a;&#x6f;&#104;&#109;&#121;&#103;&#111;&#100;&#105;&#116;&#x68;&#97;&#112;&#x70;&#x65;&#110;&#101;&#x64;&#64;&#x67;&#109;&#x61;&#x69;&#x6c;&#46;&#x63;&#111;&#109;">&#111;&#104;&#109;&#x79;&#x67;&#111;&#100;&#x69;&#x74;&#104;&#x61;&#x70;&#112;&#101;&#x6e;&#x65;&#x64;&#64;&#x67;&#x6d;&#97;&#x69;&#x6c;&#46;&#99;&#111;&#x6d;</a>&rdquo;,&ldquo;dname&rdquo;:&ldquo;&rdquo;,&ldquo;x&rdquo;:581,&ldquo;y&rdquo;:256,&ldquo;z&rdquo;:&ldquo;82a1c632.7d5e38&rdquo;,&ldquo;wires&rdquo;:[]}]</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[First 'Things' First]]></title>
    <link href="http://blog.opensensors.io/blog/2015/08/06/first-things-first/"/>
    <updated>2015-08-06T16:36:00+01:00</updated>
    <id>http://blog.opensensors.io/blog/2015/08/06/first-things-first</id>
    <content type="html"><![CDATA[<p><img src="http://blog.opensensors.io/images/ODI.jpg" /></p>

<p>I was pleased to see the <a href="http://theodi.org/data-spectrum">recent post</a> by the ODI on the open-shared-closed data spectrum since it resonates with the challenges faced at OpenSensors. To date most of our commercial projects have been at the private end of the spectrum; they are challenging, they are innovative, but they are often not ingesting open data or publishing data as an exhaust.</p>

<p>Are we worried about private IoT messaging? Not too much. Most of our private clients choose to get their own house in order first, after all typically there’s a lot of opportunity to juice existing sensors. First ‘things’ first as they say.</p>

<p>The good news is these deployments are sowing the seeds of sharing behaviours by distributing content internally, releasing data that used to terminate and die. They are unlocking data and distributing for access via API for dashboards, data science and decision support, which is the first step on a journey to openness.</p>

<p>So as a tech company how do we lead our clients and help them deliver open data strategy? We provide the tools to allow organisations to manage data entitlements pushing themselves up the data spectrum to become open. Each of our clients will make their own journey to open up their content, our job is to deliver infrastructure allowing them to manage data at a privacy that works for them.</p>

<p>This is important stuff. IoT tech companies are developing the smart city data network, and we don’t want it to be private.  We want pain free navigation from edge to edge of our urban data grid, whilst feeling secure and confident about the data we consume. Our platforms must secure data whilst facilitating its exchange and entitlement control, so what’s needed to make smart city data exchange a reality? A couple of things spring to mind, we need to &hellip;</p>

<p><strong>Evolve Topics and Communities</strong> &ndash; Expect faster adoption of sharing behaviours within trusted communities. By curating communities with shared interests expect adoption of localised data exchange, say amongst tenants of a commercial property. Communities sharing data should ease the path to universal open data.</p>

<p><strong>Evolve Exchange Mechanisms</strong> &ndash; Transparent pain free data exchange is key to delivering a functionally rich lean IoT data infrastructure, the alternative could be akin to a ‘european data mountain’ of needless and costly sensor deployments.</p>

<p>Building the tech stack for these needs is plenty of work, so as we define the business and technical models for IoT we need to act responsibly. Deploying and decommissioning software is cheap, just a couple of mouse clicks away. IoT deployments are very real, they consume natural resource, risk cluttering our environment and can loiter well past their usefulness.</p>

<p>Encouraging sharing behaviour within IoT through lean shared infrastructure will prevent waste. The alternative would be a legacy of urban junk, we made a mess of space by not decommissioning hardware, lets not do the same with our urban environment and keep it open and centred on communities.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[When Sensors and Open Data Collide]]></title>
    <link href="http://blog.opensensors.io/blog/2015/07/07/when-sensors-and-open-data-collide/"/>
    <updated>2015-07-07T10:23:00+01:00</updated>
    <id>http://blog.opensensors.io/blog/2015/07/07/when-sensors-and-open-data-collide</id>
    <content type="html"><![CDATA[<p>So I’m new to IoT having spent my career trying to find meaning in econometric data (ouch). Given I started life as a structural engineer I’m pretty excited to be working on data products with opensensors.io, feels like I’m back home again. So what’s exciting me today about where IoT and data science collide?</p>

<p>As data scientists we’re always looking at new models, new ways of shaping our view on a given data set to eek out some kind of edge. But at some point it feels like we’re chasing our tails with little hope of finding new factors to make our science better. Without new data, or at least the same data in a more granular or timely form, we’re just rehashing the same functional forms over the same content.</p>

<p>Fortunately life is about to get a whole lot more interesting as more connected devices come on line. We’re experiencing tangible innovation in IoT, we’re not talking hand wavy stuff; at opensensors.io we see hackers, hobbyists and enterprises building the next generation of smart cities with real velocity.</p>

<p>We’re also fired up since we see pretty much everyone embracing openness in their data. Exactly what open data means remains up for debate, but most agree that some flavour of open data is a prerequisite for successful smart cities.</p>

<p>It would be a pretty dumb city where you could only use the data in your own location.  So it makes sense to open pathways for data to be exchanged allowing us all to benefit from advances in technology, without a cost to our built environment. The alternative is a proliferation of street clutter used to deliver data already gathered in our smart buildings. Paradoxically not smart!  Having delivered connected buildings, transport and personal devices can expect a wave of innovation in apps and data science. So what’s would help to make this happen?</p>

<p>Communities &ndash; Architects, hackers and makers provide the crucible of IoT innovation but need support for their creative process. Helping to gong the technical pain points is great, even better is curating communities to support and challenge. Our mission is to build best of breed engineering whilst retaining our community roots leveraging platforms like github and hackster.</p>

<p>Connect existing things – Increasingly we see opensensors.io used to unlock value in existing device estates. For many enterprises it’s the ‘I’ in IoT that is new, to deliver the ‘I’ they need open, available, performant, secure and low cost messaging and data persistence.</p>

<p>Put open data to work – ‘I can’t define it, but I know it when I see it’, to paraphrase Justice Potter Stewart. The debate about what is open data will remain, what is rightly or wrongly tagged as such. But expect innovation in business models firmly founded on principles of open data. ‘Open’ may mean sharing data with your neighbour, your street, your city. Most importantly make it economically attractive for all enterprises to make data available in some form, even if it’s not ‘open’ in the purest sense.</p>

<p>We have an exciting journey ahead delivering significant change to our urban environment. Over a century ago ‘The league of American Wheelman’ catalysed improvements to America’s transport infrastructure; open data movement can deliver similar disruptive change to our urban environment. I hope open data becomes as ubiquitous as our transport network is today; in future no one will recall activists like the ODI and opensensors.io, but that would be a sign of open data’s success.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[HTTP Post]]></title>
    <link href="http://blog.opensensors.io/blog/2015/06/06/http-post/"/>
    <updated>2015-06-06T11:41:00+01:00</updated>
    <id>http://blog.opensensors.io/blog/2015/06/06/http-post</id>
    <content type="html"><![CDATA[<p>Here at OpenSensors we are committed to making it as easy as possible
to get started with your IOT projects. You can now have the ability to
post messages through OpenSensors using HTTP-POST as well as MQTT.</p>

<p>To post a message to a topic simply use this URL:
<a href="https://opensensors.io/topics/TopicID">https://opensensors.io/topics/TopicID</a> and adding the client-id and
password of your device as well as your username in the header</p>

<p>An example command using Curl is:</p>

<pre><code>curl -X POST -H 'client-id: XX' -H 'password: XXXXXXX' -H 'username: yods' https:opensensors.io/topics/users/yods/foo -d '{"value": 1}'
</code></pre>

<p>Next up is support for another great IOT protocol, CoAP!! My policy is
that we will support any open standard and protocol so if there is a
particular protocol you love feel free to send us an <a href="hello@opensensors.io">email</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[You Use Open Data Every Day]]></title>
    <link href="http://blog.opensensors.io/blog/2015/05/17/you-use-open-data-every-day/"/>
    <updated>2015-05-17T13:11:00+01:00</updated>
    <id>http://blog.opensensors.io/blog/2015/05/17/you-use-open-data-every-day</id>
    <content type="html"><![CDATA[<p>You&rsquo;ve done your hair, you&rsquo;ve picked out the perfect outfit and you&rsquo;re set  on making a great first impression. How long have I got? What tube should I get? How soon is the next bus? You check the <a href="http://www.techworld.com/news/startups/londons-citymapper-capitalises-on-decade-of-data-3467301/">CityMapper app</a> &ndash; you find a route and within seconds know exactly how long it will take to get to your hot date. You may not know it, but open data has just made your trip a lot easier.</p>

<p>Transport for London, OpenStreetMaps, Foursquare, Google Maps, Apple Maps and Cyclestreets all provide access to <a href="http://theodi.org/what-is-open-data">open data</a> for others to use. In this case, CityMapper ingests the real-time open data produced by Transport for London, remixes it with freely available open mapping data, adds a touch of their own special sauce, real-time usage and congestion data from CityMapper users, and finally curates this brew in an accessible form for the user, waiting at the bus stop. In short, the CityMapper team takes the available open data, adds value to it and provides that as a service.</p>

<p>It is not an exaggeration to claim the future development of the city is <a href="http://theodi.org/research-afternoons/show-me-the-future-of-the-built-environment-and-open-data">intertwined</a> with open data. From transport data to air quality data to real time high-street footfall, as cities become leaner, genuinely smarter and more efficient the availability of reliable high quality data will become more important than ever. Generating open data from our surroundings is unlocking value and insight from our environment, information that is all around us, for the researcher, for the app developer, for the tinkerer, for the activist.</p>

<p>For cities to succeed in building resilient systems and networks, the emerging data ecosystem in the city can&rsquo;t rely on closed data, closed systems. Devices and sensors in the city won&rsquo;t function as JawBone and FitBit do, two closed devices whose real-time data I couldn&rsquo;t access and share even if I wanted to. Open data is disrupting the digital landscape, former data-as-commodity brokers, such as <a href="http://www.landmark.co.uk/">Landmark</a>, have since fundamentally reshaped the way in which they do business, focusing on curating available data.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How to Make a Battery Last Forever…]]></title>
    <link href="http://blog.opensensors.io/blog/2015/05/12/how-to-make-a-battery-last-forever-dot-dot-dot/"/>
    <updated>2015-05-12T10:42:00+01:00</updated>
    <id>http://blog.opensensors.io/blog/2015/05/12/how-to-make-a-battery-last-forever-dot-dot-dot</id>
    <content type="html"><![CDATA[<p>Many devices in the IoT won’t be mains powered, but require some sort of supply with limited capacity: be it common batteries or rechargeable cells, energy management is a key challenge for the development of IoT products.</p>

<h2>Background</h2>

<p>The basic anatomy of a program on a microcontroller (the little green boards that run the logic of many digital devices) is an infinite loop: as long as you’re powered, do…</p>

<p>Unfortunately, even “doing nothing” costs energy. While a processor is powered, it’s always going to draw some current for the most basic housekeeping. And it’s not just the processor: voltage regulators, interfaces, nearly everything that is connected to a circuit eats up electricity, and most of it is lost in the form of heat.</p>

<p>The data in this section primarily comes from a very good blog post on <a href="http://www.gammon.com.au/power">Power saving techniques for microprocessors</a> by Nick Gammon. Let’s look at an example: Just running an empty loop on the Ardunio Uno (a commonly used microcontroller for hobbyists) draws about 50 mA. That is, with a standard 9V block (supplying 500 mAh), that Arduino can run just about 10 hours from a battery. Clearly not long enough for a hardware product that’s aimed to participate in the IoT.</p>

<p>Processor manufacturers are well aware of this issue and most platforms support a sleep mode. In case of the Arduino Uno, adding just four lines of code reduces the cost of the empty loop to 35 mA. This is still significant, but mostly owed to all the other components on the microcontroller (including a cheerfully blinking light and a wasteful voltage regulator that takes the 9V of the battery and supplies 5V to the board).</p>

<p>Fortunately, ‘real products’ don’t require all the baggage that the Arduino Uno is carrying around. The processor, the Atmel Atmega328, really just draws 0.35 mA in its most optimal sleep mode. If we don’t require particular features of the processor, this can further be reduced to less than 0.5 uA. (Note that this would allow a 500 mAh battery to drive the processor for 10 years – unfortunately, doing absolutely nothing!).</p>

<p>“But IoT devices are supposed to do things!”, I hear you say. Even more so, the hardware to send information into the Internet can be quite energy hungry – remember the times when it was recommended to switch Wifi off while you were on the road with your laptop? Now, many IoT devices, sensors in particular, only need to work in bursts.</p>

<p>Let’s take a look at one of our favourite core components in connected products: <a href="https://www.wirelessthings.net/rf-328-arduino-atmega-328-compatible-radio-transceiver-rfu-328">The RFu328 from Wireless Things</a>. It combines a barebones Atmega328 with a transceiver that can send and receive radio messages to and from an Internet-connected hub device. The processor and the radio can be sent into a deep sleep, drawing 0.5 uA. However, there’s a timer inside the radio that can trigger the Atmega328 chip and wake the entire system, ready to send or receive data at about 30 mA. We may even have to supply electric current to external sensor hardware and increase our need to more than 50 mA for a second, but for our overall energy budget that’s rather marginal – most of the time, our device will be asleep for minutes if not hours.</p>

<h2>Implementation</h2>

<p>For the standard Atmega sleep modes, consult <a href="http://www.gammon.com.au/power">Power saving techniques for microprocessors</a>.</p>

<p>The sleep modes of the RFu328 depend on a simple modification to the hardware as well as a <a href="https://github.com/CisecoPlc/LLAPSerial">library from Wireless Things</a>. In the absence of in-depth documentation, we learned a lot from PCB designs and software examples from the <a href="https://github.com/oxfloodnet">Oxford Flood Network</a>.</p>

<p>In short, the RFu328 can configure the radio to go into the extended sleep mode by sending the ATSM3 AT command. The Wireless Things library handles a lot of the high-level “+++” string handling to communicate with the SRF radio.</p>

<p>Most of the setup magic happens here:</p>

<pre><code>uint8_t setupSRF(char* sleepString) { // set Sleep mode 2
 if (!enterCommandMode()) { // if failed once then try again
 if (!enterCommandMode()) return 1;
 } 
 if (!sendCommand(sleepString)) return 2;
 if (!sendCommand("ATSM3")) return 3;
 if (!sendCommand("ATDN")) return 4;
 return 5;
 }
</code></pre>

<p>and sleepString is a combination of a configuration suffix and the millisecond sleep duration in hexadecimal notation: ATSD1388 – 5 sec; ATSD4E20 – 20 sec; ATSDEA60 – 1 min; ATSD493E0 – 5 min; ATSD1B7740 – 30 min; ATSD36EE80 – 60 min</p>

<p>Everytime the radio wakes up from this sleep, it triggers a pin of the Atmega328, and having</p>

<pre><code>LLAP.sleep(WAKE_PIN, RISING, false); // sleep until woken
</code></pre>

<p>as part of your loop() takes care of listening to that signal.</p>

<h2>Hardware</h2>

<p>So how does the WAKE_PIN (either D2 or D3) get its signal from the SRF? Via a bridge from D11. (A simple wire.) If you have a newer model of the RFu328, there’s a small field labelled ATSM3. This allows you to create a direct solder bridge to D2 or D3 without the need for the wire.</p>

<p>What other hardware modifications may be necessary? Well, most sensors have a quiescent current draw even when they’re not active. Would it not be nice to have them seperated from the battery until they’re really required? That’s exactly what we’re going to do. Transistors can be used to interrupt the flow of current until triggered, and the RFu328 has a sufficient number of pins remaining that allow for controlling (gating) as MOSFET.</p>

<p>An <a href="https://github.com/badryan/arduino/blob/master/ultrasonic_desk_sensor.ino">OpenSensors example</a> on GitHub.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Closing the Loop Between Maker &amp; Customer for Connected Devices]]></title>
    <link href="http://blog.opensensors.io/blog/2015/04/08/closing-the-loop-between-maker-and-customer/"/>
    <updated>2015-04-08T21:49:00+01:00</updated>
    <id>http://blog.opensensors.io/blog/2015/04/08/closing-the-loop-between-maker-and-customer</id>
    <content type="html"><![CDATA[<h2>Onboard IoT hardware as easy as Kindle, at a fraction of the cost.</h2>

<p>Last month we released OpenSensors’ Search and Subscribe features. This IoT Day we’re pushing our latest development, Organisations, or Orgs for short.</p>

<p>Orgs is a new feature focused on streamlining hardware  production workflows and managing large numbers of devices.</p>

<p>With OpenSensors’ Orgs, you are able to manage all of your devices and data in one place with and pretty soon you will get an at-a-glance easy device health monitoring &ndash; giving your customers a seamless user experience equivalent of the Kindle but without Amazon’s budget.  Those of you managing 1000s of devices in the wild are only too aware of how hard it is to manage the workflow between factory and individual devices all over the world.</p>

<p>We’re trying to make IoT onboarding easier for Hardware startups and connected device manufacturers. That’s why we’ve designed a production to customer workflow, think Kindle for IoT.</p>

<p><img src="http://blog.opensensors.io/images/adddevice.png" /></p>

<p>People managing organisations can now batch provision and manage their new devices.  Devices can be searched for and ‘claimed’ by your customers via the UI or API adding relevant meta-data such as location information to help you keep track of your devices and new customers once your connected devices are out in the wild.</p>

<p>It’s an exciting feature, and we hope you’re just as excited as we are.  We want to save you time and effort and also enable you to get your connected devices to market quicker and cheaper.</p>

<p>As some of you may have noticed, we released a stripped down Alpha version of Orgs in our last release. We’ve learned from your feedback.</p>

<p>And we’re not finished yet, we have a lot of plans for Orgs and this is the first step in the journey.  To celebrate IOT day we are giving away 3 months worth of Organisational hosting and functionality to IoT startups.  Get in touch on <a href="&#x6d;&#97;&#105;&#108;&#116;&#x6f;&#58;&#104;&#x65;&#108;&#108;&#111;&#64;&#111;&#112;&#x65;&#x6e;&#x73;&#x65;&#x6e;&#115;&#x6f;&#x72;&#x73;&#x2e;&#105;&#x6f;">&#104;&#x65;&#x6c;&#108;&#111;&#x40;&#111;&#112;&#101;&#110;&#115;&#101;&#x6e;&#x73;&#111;&#x72;&#x73;&#46;&#x69;&#x6f;</a> for a voucher.</p>

<p>For more details about Organisations and how to use them check out our
<a href="https://opensensors.io/help/">help pages</a></p>

<p>Happy IoT Day!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Resin.io]]></title>
    <link href="http://blog.opensensors.io/blog/2015/04/02/resin/"/>
    <updated>2015-04-02T08:38:00+01:00</updated>
    <id>http://blog.opensensors.io/blog/2015/04/02/resin</id>
    <content type="html"><![CDATA[<p>When you are working with many connected devices updating the software on them can be tedious. Sometimes sensors are in hard to reach locations and having to get to all of them to update a little bit of code can be a nightmare. Resin.io has a solutions for this. They have made it quick and easy to update the code running on all your connected linux devices. This is very useful for Raspberry Pi based sensors.</p>

<p>Here we’ll explain how we used Resin.io to get code running on our devices publishes to our OpenSensors topic.</p>

<h2>Getting Started</h2>

<p>Firstly we checked out the Resin getting started guide found here:</p>

<p><a href="http://docs.resin.io/#/pages/gettingStarted.md">http://docs.resin.io/#/pages/gettingStarted.md</a></p>

<p>We needed to reformat the SD before we got it to boot properly.</p>

<p>Following the instructions on the getting started guide we pushed the node.js text2speech project they suggested. We were surprised at how easy it made getting code running on your PI.</p>

<p>The next step was to push some python code and get it running. We used a barebones hello world python script with the required docker file which we found here:</p>

<p><a href="https://github.com/alexandrosm/hello-python">https://github.com/alexandrosm/hello-python</a></p>

<p>That too was easy to get working.</p>

<h2>Communicating with OpenSensors</h2>

<p>To get the extra packages needed to communicate with OpenSensors we added some lines to the docker file:</p>

<p>RUN apt-get install -y python-pip
RUN pip install paho-mqtt</p>

<p>the -y was needed to select the yes option on the pip install.</p>

<p>Then we added some code that uses the paho-mqtt library in the python script</p>

<p>You can check it out here</p>

<p><a href="https://github.com/louischaman/Resin_HelloOSIO">https://github.com/louischaman/Resin_HelloOSIO</a></p>

<p>You’ll have to change the username and device ID and password to get it working.</p>

<p>It created the image uploaded it and started running without a
hitch. We could see that it was working because the messages were
appearing on the OpenSensors online dashboard for my topic. Resin.io
is a great product that solves a very real problem in a clever way, I
will be adding it to my toolkit.</p>

<p>Does this help you solve a problem you’ve been having with your
connected sensors? If so get contact and let us know what you are up
to on <a href="&#x6d;&#x61;&#105;&#108;&#x74;&#x6f;&#58;&#x68;&#101;&#108;&#x6c;&#x6f;&#64;&#111;&#112;&#101;&#110;&#115;&#x65;&#x6e;&#115;&#x6f;&#x72;&#x73;&#x2e;&#105;&#111;">&#x68;&#101;&#x6c;&#108;&#x6f;&#x40;&#x6f;&#x70;&#101;&#110;&#115;&#x65;&#x6e;&#115;&#x6f;&#114;&#115;&#x2e;&#105;&#111;</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Open and Transparent]]></title>
    <link href="http://blog.opensensors.io/blog/2015/03/27/open-and-transparent/"/>
    <updated>2015-03-27T00:18:00+00:00</updated>
    <id>http://blog.opensensors.io/blog/2015/03/27/open-and-transparent</id>
    <content type="html"><![CDATA[<h1>Open And Transparent</h1>

<p>It’s been an interesting few days in OpenSensors HQ. My fairly harmless comment about privacy and security for the Internet of things on Twitter turned into a fracas.  A fairly prominent blogger and activist, Aral Balkan, took issue with our use of the word Open in our company name.  Twitter is not the best medium for nuanced debate so I wanted to address the points raised.</p>

<p>The central point of Aral’s comments can be summed up by his tweet
<em>If you have a closed platform, don’t call it open. Is that too much to ask for?</em></p>

<p>For clarity, here is why we are proud to call ourselves <strong>Open</strong>Sensors.</p>

<h2>Who we are</h2>

<p>We are an Open Data and Internet of Things startup incubated in the
Open Data Institute, founded by our hero Sir Tim Berners Lee.  If you have never come
across open data please check out his
<a href="http://www.ted.com/talks/tim_berners_lee_on_the_next_web?language=en">great talk</a>
about what it is and also see the great <a href="https://okfn.org/opendata/">Open Knowledge Foundation&rsquo;s write up</a>.</p>

<p>The <a href="http://en.wikipedia.org/wiki/Internet_of_Things">Internet of Things (IoT)</a> is a very broad term for
connecting day to day objects and sensors to the internet. In the IoT world open refers to Open Source Software (OSS), Open Data, Open Hardware, Open Protocols and the Open Web. The common thread that holds these ideals together is that accessibility is key to creating value and benefit.</p>

<p>We strongly believe in all of these ideals. We write open source code and we develop firmware for Open Hardware devices and our guiding principle is to support Open Internet of Things and Web protocols.</p>

<p>OpenSensors aims to create a real time public data exchange.  Most public sensor data sets are currently sitting in silos and we will make them available for reuse by anyone with Open Data Licences. Publishers of data sets include individuals, cities, etc  Data such as Air Quality information, flooding, parking etc is so much more useful when it’s accessible and reusable by as many people and services as possible.</p>

<p>In order to do this, we have built a hugely scalable core, thanks to existing Open Source projects.  We use standard web technologies such as HTTP as well as Server Sent Events for easy real time transfer of data between sensors and the web. In addition, we use Open Sensor protocols such as MQTT to enable M2M applications and we will soon have support for another great open protocol CoAP.</p>

<h2>Will all our code be Open?</h2>

<p>We will develop open source software (including our core azondi). We
will also contribute back in some way to the huge amount of open source software we use such as Cassandra, Elastic Search, Postgres,
Netty, a ton of <a href="http://clojurewerkz.org/">clojurewerkz projects</a> and
have incubated <a href="https://github.com/juxt/cylon">Cylon</a>, a security
library, from Alpha.  We have plans to release a ton of other OSS
projects for things that we needed to scratch our itch.  We recognise
that we stand on shoulders of the giants of the computer science world.</p>

<p>All that being said please be aware that we are not a social
enterprise and there will be parts of our code base that will be
private. We are ultimately a for profit company and our aim is to
create a sustainable business model for an engineering led business to
thrive.</p>

<ul>
<li>We want to hire amazing developers to solve hard problems, enable them to unleash their creative energies and love the product.</li>
<li>We pay everyone from interns upwards a sustainable wage.</li>
<li>We value diversity and spend time and money organising community groups for free to give back.</li>
<li>We do not charge to speak at or to arrange community events.</li>
<li>We run paid training events where at least 30% of attendees places
will fully or in part covered by Open Sensors for those that don&rsquo;t have the means to pay the full price.</li>
<li>We do not depend on government funding and our pricing structure is very clear <a href="https://opensensors.io/pricing.">https://opensensors.io/pricing.</a></li>
</ul>


<p>We have a freemium model around open data that will hopefully create a
lot of value to a lot of people.  We also will enable our paid clients to build connected products for a charge in order to pay for servers, salaries, office costs, etc.</p>

<p>We aim to find enough people to give us their hard earned money by building an amazing product. It is that simple. We do not resell private data or try to create revenue from insight into private user behavior.</p>

<h2>Do we have the right to call ourselves Open and claim a seat at the table?</h2>

<p><strong>Hell Yes!</strong> No one gets to play at un-appointed gatekeeper in <strong>our</strong>
communities especially using exclusionary language and labels, not even
the founder of the web and open data.</p>

<p><img src="http://blog.opensensors.io/images/finished.gif" /></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[European Parliament Approves eCall Technology]]></title>
    <link href="http://blog.opensensors.io/blog/2015/03/17/european-parliament-approves-ecall-technology/"/>
    <updated>2015-03-17T10:57:00+00:00</updated>
    <id>http://blog.opensensors.io/blog/2015/03/17/european-parliament-approves-ecall-technology</id>
    <content type="html"><![CDATA[<p><img src="http://blog.opensensors.io/images/autobahn.jpg" /></p>

<p>European Parliament approves eCall connected car platform</p>

<p>The Internet of Things threatens to revolutionise everyday life, embedding and imbuing everyday objects and the world around us with sensors, software and electronics. Through machine-to-machine communication, automation and advanced analytics, we are able to understand and scrutinise our environment and the processes which surround us in ways never conceived. From high level analysis allowing automated condition monitoring of critical engine parts, giving engineers the tools to reduce costly operational downtime to embedding real-time sensors in bridges to predict stresses and flooding. Beyond the Cloud, the Internet of Things brings the internet to the everyday, and there are clear use cases for such technologies in the realm of road safety.</p>

<p>This is where eCall comes in. eCall is a European Commission initiative coming into force on 31 March 2018, making mandatory the deployment of internet-connected sensors into cars that enable emergency services to be immediately contacted and requested automatically after a serious road incident within the European Union. EC VP for Digital, Neelie Kroes, argues “EU-wide eCall is a big step forward for road safety. When you need emergency support it&rsquo;s much better to be connected than to be alone.” eCall will drastically cut European emergency service response times, even in cases where passengers are unable to speak through injury, by sending a Minimum Set of Data (MSD), including the exact location of the crash site.</p>

<p>The deployment of eCall is one of most ambitious EU-wide programs since the 2007 enlargement, rolling out implementation of the eCall platform to some 230 million cars and 33 million trucks in the European Union. Implementation of eCall at a European level (including Norway, Switzerland etc) however benefits consumers and industry through reducing costs due to economies of scale, reducing the installation cost to as little as €100. The basic pan-European eCall service will be free at the point of use for equipped vehicles. It is likely that the eCall technology platform (i.e., positioning, processing and communication modules) will be exploited commercially too, for stolen vehicle tracking, dynamic insurance schemes, eTolling and emerging forms of vehicle-to-vehicle (V2V) and vehicle-to-infrastructure (V2I) road safety systems. eCall will be based upon a standardised platform, one system for the entirety of Europe, aimed at enabling both car and telecoms industries a quick roll out and to avoid crippling OEM versioning and patching <a href="https://www.ftc.gov/news-events/blogs/techftc/2015/02/whats-security-shelf-life-iot?page=1">issues</a>.</p>

<p>In terms of privacy, the basic eCall system has been given the green light by the European Commission on the express condition that <a href="http://ec.europa.eu/information_society/newsroom/cf/dae/document.cfm?doc_id=5963">firm data protection safeguards</a> are in place and that the sensor-equipped vehicles will not push data to external servers except in the case of a crash, or by the actions of the driver, in order to contact the PSAP (Public Safety Answering Point) and will lie dormant until that point. The data transmitted to the emergency services, described as MSD, Minimum Set of Data, are those strictly needed by the emergency services to handle the emergency situation. While in normal operation mode the system is not registered to any telecoms network and no mediating parties have access to the MSD that is transmitted to the PSAPs.</p>

<p>Today the European Parliament&rsquo;s Internal Market and Consumer Protection Committee MEPs <a href="http://www.europarl.europa.eu/news/en/news-room/content/20150316IPR34756/html/Internal-market-MEPs-green-light-life-saving-emergency-call-system-for-cars">voted on and approved eCall</a> pushing forward a life-saving Internet of Things technology that will significantly improve European road safety. The UK Government however, has not followed suit, whilst welcoming the implementation in other member states, feels that &ldquo;it is not cost-effective &hellip; given the increasing responsiveness of our road network, we feel that smart motorways do the same thing,&rdquo; <a href="http://telematicsnews.info/2015/03/12/uk-minister-says-ecall-would-cost-370-million_m6123/?utm_source=twitterfeed&amp;utm_medium=twitter">remarked Minister Perry</a> on behalf of the Department of Transport. Whilst it can be argued that &lsquo;Smart Motorways&rsquo; are far from a worthy substitute to connected cars &amp; V2V/V2I systems, the UK&rsquo;s criticism belies a certain caution with regards to green-lighting <a href="http://www.independent.co.uk/life-style/health-and-families/health-news/nhs-pulls-the-plug-on-its-11bn-it-system-2330906.html">large and costly IT projects</a>. Only time will tell whether the UK Govt&rsquo;s decision has left those drivers not on Britain&rsquo;s Smart Motorways in the lurch.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Measuring Air Quality on Opensensors]]></title>
    <link href="http://blog.opensensors.io/blog/2015/02/22/measuring-air-quality-on-opensensors/"/>
    <updated>2015-02-22T22:22:00+00:00</updated>
    <id>http://blog.opensensors.io/blog/2015/02/22/measuring-air-quality-on-opensensors</id>
    <content type="html"><![CDATA[<h3><strong>Measuring the air quality of the ODI using an Arduino and a Shinyei PPD-42</strong></h3>

<p>So, whilst thinking of a good demonstration for the Opensensors platform, we thought why not see how polluted our workplace is by hooking up a sensor to publish a continuous data stream to the Opensensors messaging broker.<br/>
For this we need an easy to pick up and use sensor,  we settled on the Shinyei PPD-42. We&rsquo;ll use this in order to measure the number of potentially hazardous small particulates in the air, with an arduino connected to a linux PC (or Raspberry PI).</p>

<p>To run this mini-project you will need:</p>

<ol>
<li>Shinyei PPD-42</li>
<li>Arduino UNO</li>
<li>Computer with Linux installed (you can use a Raspberry PI)</li>
</ol>


<p>We are basing this run-through on a project called DustDuino that uses the Shinyei PPD-42 sensor with an arduino and a wifi module. Check it out <a href="http://www.mentalmunition.com/2013/10/measure-air-pollution-in-your-home-or.html">here</a>. We used this project as our reference when setting up the sensor and writing the Arduino code.</p>

<p><img src="http://blog.opensensors.io/images/pic6.jpg" /></p>

<p>Firstly we follow step 2 of the instructions for hooking up the sensor to the Arduino.
Then we download the code from the projects <a href="https://github.com/NodeJournalism/DustDuino">github repository</a> by opening the link for the code DustDuinoSerial.ino selecting raw and saving that page.</p>

<p><img src="http://blog.opensensors.io/images/pic1.png" /></p>

<p>Opening this up in the arduino IDE, we now upload it to our Arduino UNO by connecting the Arduino and pressing upload.</p>

<p><img src="http://blog.opensensors.io/images/pic2.png" /></p>

<p>You can check the data is coming in by using the Arduino IDE’s serial monitor.</p>

<p><img src="http://blog.opensensors.io/images/pic3.png" /></p>

<p>We then need to figure out how to send the incoming serial message to the Opensensors message broker.</p>

<p>To do this we chose to write a Python script. We used the <a href="https://pypi.python.org/pypi/paho-mqtt">Mosquitto Python module</a>.
I’m going to assume that you already have Python installed, as it comes pre-packaged on most versions of Linux.
If you don’t have it already, you&rsquo;ll need to install pip to download and set up the Mosquitto python module. On Ubuntu or Debian this can be done with the following command:</p>

<pre><code>sudo apt-get install python-pip
</code></pre>

<p>Once pip is installed we can install the Mosquitto python client module using the following command:</p>

<pre><code>sudo pip install paho-mqtt
</code></pre>

<p>You can find out how to use the python module by having a read through the website which we’ve linked above.
Writing and compiling python is really easy.</p>

<h3>Hello Python World</h3>

<p>Open up your favorite plaintext editor. Enter the line:</p>

<pre><code>print “Hello World”
</code></pre>

<p>Save it as hi.py. Then in terminal, navigate to your document and enter the command:</p>

<pre><code>python hi.py
</code></pre>

<p>You should see your “Hello World” response. It’s that easy.</p>

<h3>Hello Opensensors</h3>

<p>To use the Mosquitto client python module we can run the following code to test out publishing. You’ll need to replace my username “Louis” (keeping the speech marks), and password with your details:</p>

<p>The mosquitto library we need to communicate with the Opensensors message broker:</p>

<pre><code>import paho.mqtt.client as mqtt
</code></pre>

<p>Initialise the client option with our client ID of our device:</p>

<pre><code>mqttc = mqtt.Client(client_id="939")
</code></pre>

<p>Set our username and password:</p>

<pre><code>mqttc.username_pw_set("Louis", password="AbcDEFgH")
</code></pre>

<p>Connect to the Opensensors server:</p>

<pre><code>mqttc.connect("opensensors.io")
</code></pre>

<p>Publish a message to say hello:</p>

<pre><code>mqttc.publish("/users/Louis/test2", payload="Hello Opensensors!", qos=0, retain=False)
</code></pre>

<p>Disconnect:</p>

<pre><code>mqttc.disconnect();
</code></pre>

<p>Success, you should now have a functioning sensor :)</p>

<p><img src="http://blog.opensensors.io/images/pic4.png" /></p>

<p>Next we need to get the serial working. To find out what your arduino serial port looks like we executed  following command into terminal:</p>

<pre><code>dmesg | grep tty
</code></pre>

<p>The output was something like this&hellip;</p>

<pre><code>[    0.000000] console [tty0] enabled
[ 3522.192687] cdc_acm 7-1:1.0: ttyACM0: USB ACM device
</code></pre>

<p>The second line has details of our Ardiuno. The ttyACM0 is the device name and ‘/dev/ttyACM0’ is the serial port.</p>

<p>To open and read the serial port Python makes it really easy. You can run a little test to check whether it is working by using the following code:</p>

<p>For communication with the Arduino we need to use the serial library:</p>

<pre><code>import serial
ser = serial.Serial(‘/dev/ttyACM0’) # open first serial port
while True:
print ser.readline()        # prints each line it reads from serial
</code></pre>

<p><img src="http://blog.opensensors.io/images/pic5.jpg" /></p>

<p>Finally we just need to hack together the two pieces. Here is the code we used:</p>

<pre><code>import serial
import paho.mqtt.client as mqtt
import time

mqttc = mqtt.Client(client_id="939")
mqttc.username_pw_set("Louis", password="AbcDEFgH")
mqttc.connect("opensensors.io")

ser = serial.Serial('/dev/ttyACM0')  # open first serial port
while True:
message= ser.readline()
print message
mqttc.publish("/users/Louis/ODI/airquality", payload=message, qos=0, retain=False)
time.sleep(1);
</code></pre>

<p>Running this we were publishing our sensor data to Opensensors!</p>

<p>WE recommend adjusting the Arduino code to output the data in JSON format. This will make it easier to read and add functionality.</p>

<p>You can check out the topic producing Open Data we created <a href="https://opensensors.io/topics/users/Louis/ODI/airquality">here</a>!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Search Has Landed]]></title>
    <link href="http://blog.opensensors.io/blog/2015/02/16/search-has-landed/"/>
    <updated>2015-02-16T10:51:00+00:00</updated>
    <id>http://blog.opensensors.io/blog/2015/02/16/search-has-landed</id>
    <content type="html"><![CDATA[<p>There’s a lot of data out there. We’re doing our best to help you discover it. With the latest release of OpenSensors, users are now able to search the OpenSensors database of thousands of real-time public Open Data feeds and subscribe to Topics of interest.</p>

<p>To search the OSIO datasets simply type your query into the search box at the top of the site. A search query can relate to any parts of a Topic, name, unit, description, or the user who created the Topic.</p>

<p>Once found, you can subscribe to a Topic by clicking on the star icon allowing you to build a library of bookmarked Topics of interest that you can recall at any time in the new Favourite Topics page.</p>

<p>The savvy user will note the new Organisation page too. Organisations will enable you to own a topic tree for your business or citizen science group under</p>

<pre><code>/orgs/&lt;business name&gt;/*
</code></pre>

<p>but other people such as members of your group or customers can publish to the organisations topic tree, the clearest example of this is Github’s organisations.  Organisations will help you manage your products and assets out in the wild whether in cities or people’s homes.</p>

<p>This is the first, very much alpha, iteration of the seamless connected experiences we are building throughout the next releases over the coming days, along with Featured Feeds and dynamic data feed visualisations.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[OwnTracks Journey - Part One]]></title>
    <link href="http://blog.opensensors.io/blog/2015/01/20/owntracks-journey-part-one/"/>
    <updated>2015-01-20T12:56:00+00:00</updated>
    <id>http://blog.opensensors.io/blog/2015/01/20/owntracks-journey-part-one</id>
    <content type="html"><![CDATA[<p>Today we’re going to look at using the OwnTracks app within the OpenSensors platform. <a href="http://owntracks.org">&lsquo;OwnTracks&rsquo; (formerly MQTTitude)</a> allows you to keep track of your connected devices location. The app is open-source and uses open protocols for secure and private communications. First off we’ll start by installing the OwnTracks app on our device, I’m using a Nexus tablet for this attempt. Also, make sure your device <em>Location Data is enabled</em>. Whilst we’re waiting for that to sort itself out, let’s open up OpenSensors.io.</p>

<p>If you haven’t already, create a new account, when you’re in &ndash; select Devices on the nav bar to the left. You should see the interface below.</p>

<p><img src="http://blog.opensensors.io/images/createdev.jpg" /></p>

<p>Click <em>Create New Device</em>, give it a name and, optionally, a description (what is your device?). Importantly, choose whether you’d like to publish your data as public Open Data or Private Data. Whilst we’re on this screen, take note of the <em>Client ID</em> and <em>Password</em>, if you forget or lose your device password, don’t worry, just come back to <a href="https://opensensors.io/devices">this page</a>, select your device and click the small padlock icon on the far right next to the bin, this will reset your password.</p>

<p>Now we’ve got that sorted, let’s run OwnTracks on our device. You should see this screen. In the top right we see two buttons, on the left is the Report button, essentially submitting data to our server, and the right, options. Click options and then preferences.</p>

<p><img src="http://blog.opensensors.io/images/owntracks.png" /> alongside <img src="http://blog.opensensors.io/images/owntrackspref.png" /></p>

<p>As you can see we’re currently disconnected from any network, let’s change that. Firstly, click <em>Advanced</em> and select <em>Advanced connection preferences</em>. Now go back to preferences menu and click <em>Connection</em> and input the following &ndash; input your own <em>username</em>, <em>Device ID</em> and <em>Device Password</em> as displayed earlier on OpenSensors.io device manager, and type OpenSensors.io as <em>Host</em> and 1883 as <em>Port Number</em>. Change <em>Connection Security</em> to None. These are OSIO’s settings. You can go back to Preferences and change the automatic reporting interval etc.</p>

<p><img src="http://blog.opensensors.io/images/owntracksconnection.png" /></p>

<p>We’re all set. Now let’s go back to our devices page, and scroll down to the <em>Events</em> box, whereas before it looked this…</p>

<p><img src="http://blog.opensensors.io/images/events1.jpg" /></p>

<p>We should now be publishing data &ndash; test your new connected device, publishing your location data by pressing the <em>Report</em> button on the OwnTracks main screen. Each time you submit data through the app you should see…</p>

<p><img src="http://blog.opensensors.io/images/eventssuccess.jpg" /></p>

<p>You’re now publishing Open Data through the OpenSensors.io messaging broker! From this you are able to create smart apps and projects using your data, all we need to do now is have your app and project subscribe to our twitter hashtags of the IoT, topics &ndash; but you’ll have to wait and see until part two of our OwnTrack journey!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Installing an Arduino Wifi Shield]]></title>
    <link href="http://blog.opensensors.io/blog/2014/11/19/installing-an-arduino-wifi-shield/"/>
    <updated>2014-11-19T20:07:00+00:00</updated>
    <id>http://blog.opensensors.io/blog/2014/11/19/installing-an-arduino-wifi-shield</id>
    <content type="html"><![CDATA[<p>After a few Arduino projects (mainly blinking LEDs and connecting sensors) I tried
to connect my Arduino to the internet using a Wifi shield!</p>

<p>I started by looking at Arduino Wifi shield <a href="http://arduino.cc/en/Guide/ArduinoWiFiShield">instructions</a>.</p>

<p>Then I physically connected my Arduino and Wifi shield:</p>

<p><img src="http://blog.opensensors.io/images/arduino-wifishield.jpg" /></p>

<p>As a test I wanted to scan for available networks using the example code on <a href="http://arduino.cc/en/Guide/ArduinoWiFiShield#toc5">this</a>
Arduino Wifi shield webpage.</p>

<p>I mentioned in a previous blog <a href="http://blog.opensensors.io/blog/2014/09/13/getting-started-with-arduino-on-linux/">post</a>
I had an issue with the Arduino IDE and now use <a href="http://inotool.org/">inotool</a>.
It enables to code for Arduino in your text editor/IDE of choice and compile and
upload code from the command line (but it still needs the Arduino IDE to be installed).</p>

<p>Here&rsquo;s how I start a project with inotool:</p>

<pre><code>~$ mkdir new_project && cd new_project</code>
<code>~$ ino init</code></pre>


<p>Here&rsquo;s the structure of my project afterwards:</p>

<p><img src="http://blog.opensensors.io/images/directory_structure.png" /></p>

<p>I can then edit the code in src/sketch.ino. In that case I just copied/pasted
the code from Arduino&rsquo;s example:</p>

<p><img src="http://blog.opensensors.io/images/Test_wifishield.png" /></p>

<p>I built as usual using this command: <pre><code>~$ ino build</code></pre> &hellip; and got
the following error:</p>

<p><img src="http://blog.opensensors.io/images/build_error_wifi.png" /></p>

<p>=> It seemed there was a conflict between the Ethernet and WiFi Libraries.</p>

<p>&hellip; Then I kind of lost it (O_O) and tried all those things:</p>

<ul>
<li>bypassing both Arduino IDE and inotool by using a Makefile for compiling Arduino (<a href="http://hardwarefun.com/tutorials/compiling-arduino-sketches-using-makefile">http://hardwarefun.com/tutorials/compiling-arduino-sketches-using-makefile</a>)
   => and I got lost down makefile rabbit hole&hellip;</li>
<li>updating (or trying to update) the wifi shield firmware using Arduino&rsquo;s <a href="http://arduino.cc/en/Hacking/WiFiShieldFirmwareUpgrading">instructions</a> and blog posts.
  => when I finally managed it, it didn&rsquo;t have any effect&hellip;</li>
<li>downgrading from Arduino IDE version 1.0.5 to 1.0.2 (older versions are found <a href="http://arduino.cc/en/Main/OldSoftwareReleases">here</a>).
  => no improvement really&hellip;</li>
</ul>


<p>I went back and forth between those solutions and at best I could compile the sketch but my MAC address was 0.0.0.0 (same for my IP address)!</p>

<p><strong>Here&rsquo;s how it finally worked for me:</strong></p>

<ul>
<li>I downgraded to Arduino IDE version 1.0.1.</li>
<li>Copied &ldquo;arduino-1.0.1&rdquo; in usr/share/ and renamed it to &ldquo;arduino&rdquo; so that the path to the IDE was /usr/share/arduino/.</li>
<li>I added wifishield/ folder from <a href="https://github.com/arduino/Arduino/tree/master/hardware/arduino/firmwares/wifishield">https://github.com/arduino/Arduino/tree/master/hardware/arduino/firmwares/wifishield</a> to /usr/share/arduino/hardware/arduino/firmwares/.</li>
<li>I added the WiFi library from <a href="https://github.com/arduino/Arduino/tree/master/libraries/WiFi">https://github.com/arduino/Arduino/tree/master/libraries/WiFi</a> to /usr/share/arduino.</li>
<li>I upgraded the firmware (not sure if necessary) => <em>Note</em> : you need a USB 2.0 Mini B cable to link the wifi shield directly to your computer!

<ul>
<li> here are the instructions to install dfu-programmer: <a href="https://github.com/dfu-programmer/dfu-programmer">https://github.com/dfu-programmer/dfu-programmer</a></li>
<li> and you can get the latest wifi shield scripts from <a href="https://github.com/arduino/Arduino/tree/master/hardware/arduino/firmwares/wifishield/scripts">https://github.com/arduino/Arduino/tree/master/hardware/arduino/firmwares/wifishield/scripts</a></li>
<li> replace your scripts in /usr/share/arduino/hardware/arduino/firmwares/wifishield/scripts/ with the ones from Arduino Github repo.</li>
<li> close the J3 jumper on the shield (***),
   then run:
   <pre><code>~$ sudo ./ArduinoWifiShield_upgrade.sh -a /usr/share/arduino -f all</code></pre></li>
</ul>
</li>
</ul>


<p>Yay! (^o^) You can now try new projects like creating a <a href="http://arduino.cc/en/Tutorial/WiFiWebServer">webserver</a> or sending sensor data via internet!</p>

<br>


<p>(***) In case you wonder what a <strong>J3 jumper</strong> looks like,
those pictures could be useful to you:</p>

<ul>
<li>Here the J3 jumper is open (for when the shield communicate with the Arduino):</li>
</ul>


<p><img src="http://blog.opensensors.io/images/j3_opened.jpg" /></p>

<ul>
<li>Here the J3 jumper is closed (or in programming mode, to update the firmware):</li>
</ul>


<p><img src="http://blog.opensensors.io/images/j3_closed.jpg" /></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[An Open Data Startup]]></title>
    <link href="http://blog.opensensors.io/blog/2014/10/30/an-open-data-startup/"/>
    <updated>2014-10-30T18:00:00+00:00</updated>
    <id>http://blog.opensensors.io/blog/2014/10/30/an-open-data-startup</id>
    <content type="html"><![CDATA[<p>In that intense start up haze we occupy, the fact that
OpenSensors has turned 1 this month completely passed me
by! I feel that occasion should be marked with at least a post to
reflect on how far we have come in a year.</p>

<h2>An ODI startup <img src="http://blog.opensensors.io/images/odi.png" /></h2>

<p>The highlight of the year has to be our inclusion to the
<a href="http://opendatainstitute.org/">Open Data Institute&rsquo;s</a> startup
program.</p>

<p>The ODI&rsquo;s mission is to unlock the potential of public data held by
governments and businesses to help solve the world&rsquo;s hard
problems. As our mission is to build a connected world based on open
data and technologies, being part of the ODI&rsquo;s network of like minded
people is the natural home for OpenSensors.</p>

<h2>Engineering Middleware is Hard</h2>

<p>The original middleware we designed and prototyped for OpenSensors has long been thrown
out, actually rewritten several times. We have spent hundreds of
engineering hours making it fast and secure. We can now comfortably process millions of
messages per second from hundreds of thousands of devices.  And most
importantly we let each of our users get their own real time feeds of data that they are interested in.</p>

<p>If you told me a year ago that it would take this long to build the
middleware we would be happy with, how I would have laughed at you&hellip;.</p>

<h2>Hardware is very Hard</h2>

<p>After spending some time working under the radar, towards the middle of 2014 the Internet
of Things
<a href="http://www.forbes.com/sites/gilpress/2014/08/18/its-official-the-internet-of-things-takes-over-big-data-as-the-most-hyped-technology/">hypecycle</a>
suddenly went into overdrive.</p>

<p>That being said designing and manufacturing hardware products at scale
is a significantly different proposition to scaling software. The
skill sets necessary to build and manufacture electronics products is
rare and laborious. We have found ourselves in the surprising position
of prototyping hardware for clients and cities as well as learning the
process of manufacturing.</p>

<h2>Aims for the coming year</h2>

<p>Our central ambition for the next year is to make it very easy for
people to find and contribute to rich sources of real time data that is of interest to them.</p>

<p>We have some exciting partnerships and projects with various cities and
groups in parking, disability accessibility and smart buildings all publishing open data. We
also want to help showcase the excellent work of the many community
based environmental sensing projects.</p>

<h2>Sunsetting the early access period</h2>

<p>As of the 1st of December 2014, we will be charging for private use of the
service. Open Data projects will always be free. Private projects
will incur a small monthly cost towards the service based on the
number of devices you run.</p>

<p>For a full details of the pricing, see <a href="https://opensensors.io/pricing">https://opensensors.io/pricing</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Getting Started With Arduino on Linux (Ubuntu)]]></title>
    <link href="http://blog.opensensors.io/blog/2014/09/13/getting-started-with-arduino-on-linux/"/>
    <updated>2014-09-13T07:56:00+01:00</updated>
    <id>http://blog.opensensors.io/blog/2014/09/13/getting-started-with-arduino-on-linux</id>
    <content type="html"><![CDATA[<p>Ordered and received your Arduino Uno (I actually received it a while ago!) now what? The first step is to rush to the <a href="http://arduino.cc/en/Guide/HomePage">&lsquo;Getting Started&rsquo;</a> page on Arduino&rsquo;s website.</p>

<p>To install Arduino on Linux (I&rsquo;m running Ubuntu 14.04) visit the <a href="http://playground.arduino.cc/Learning/Linux">wiki page</a> with instructions for most Linux distributions. I used the instructions for Ubuntu 12.04 or newer and ran <pre><code>~$ sudo apt-get update &amp;&amp; sudo apt-get install arduino arduino-core</code></pre>
Afterwards you should be able to plug your Arduino and use Arduino IDE to code/upload code to it. It didn&rsquo;t work directly for me. I couldn&rsquo;t launch Arduino IDE by clicking the logo so I tried the CLI <pre><code>~$ arduino</code></pre> Here&rsquo;s the error it returned:</p>

<blockquote><p>Exception in thread &ldquo;main&rdquo; java.lang.ExceptionInInitializerError.</p></blockquote>

<p><img src="http://blog.opensensors.io/images/arduino_bug1.png" /></p>

<p>I found a solution on <a href="http://askubuntu.com/questions/26474/unable-to-install-arduino">AskUbuntu</a> forum. I downgraded from java 7 to java 6 <strong>(***)</strong> using the command: <pre><code>~$ sudo update-alternatives &mdash;config java</code></pre>
I then managed to launch Arduino from the CLI (I was asked to authenticate) and tried to upload a code example to my Arduino (Files > Examples > 01.Basics > Blink).
I received this error message:</p>

<blockquote><p>processing.app.SerialNotFoundException: Serial port &lsquo;COM1&rsquo; not found. Did you select the right one from the Tools > Serial Port menu?</p></blockquote>

<p><img src="http://blog.opensensors.io/images/arduinobug2.png" /></p>

<p>In Tools I saw that Serial Port was greyed out so I couldn&rsquo;t even select the port.
from <a href="http://stackoverflow.com/questions/19322432/arduino-tools-serial-port-greyed-out">Stackoverflow</a> I found that to give read and write privilege on the usb port I could run Arduino with the administrator privileges.
And so I used <pre><code>~$ sudo arduino</code></pre> &ndash;> It worked! It blinked!
Here&rsquo;s a proof:</p>

<p><img src="http://blog.opensensors.io/images/arduino_blinks.jpg" /></p>

<h2>Troubleshooting</h2>

<ul>
<li>Check your Arduino IDE settings: Tools > Board (the right borad is select), Tool > Serial Port (the right port for your device is ticked).</li>
<li>Check all dependencies were downloaded with arduino and arduino-core .

<ul>
<li>Arduino&rsquo;s dependencies: arduino-core, default-jre, libjna-java, librtx-java</li>
<li>Arduino-core&rsquo;s dependencies: avr-libc, avrdude, gcc, gcc-avr</li>
</ul>
</li>
<li>Also try LadyAda&rsquo;s <a href="http://www.ladyada.net/learn/arduino/help.html">help page</a>.</li>
</ul>


<p><strong>(***) Well, well. You might realise later that you actually need java 7 for another program to work! But fear not, see the alternatives below.</strong></p>

<h2>Alternatives to Arduino IDE</h2>

<p><a href="http://arduino.cc/en/main/software">Arduino IDE</a> is based on java but luckily there other tools to write code for Arduino.</p>

<p>I tried <a href="http://inotool.org/">Ino</a> which is written in Python and is a command line tool and allows to write code in any text editor.
It is straightforward to install with instructions given. You will need to install picocom program if you don&rsquo;t have it <pre><code>~$ sudo apt-get install picocom</code></pre>
There are other <a href="https://learn.sparkfun.com/tutorials/alternative-arduino-interfaces">alternatives</a> to the Arduino IDE like <a href="https://codebender.cc/">Codebender</a> which is an online development platform.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[IOT in the City]]></title>
    <link href="http://blog.opensensors.io/blog/2014/03/12/iot-in-the-city/"/>
    <updated>2014-03-12T13:41:00+00:00</updated>
    <id>http://blog.opensensors.io/blog/2014/03/12/iot-in-the-city</id>
    <content type="html"><![CDATA[<h2>Architecting Internet of Things Software for Cities</h2>

<p>We are often asked to advise on how best to build scalable products for
the Internet of Things, specifically to provide City wide services. City scale projects, also marketed as Smart or Future
Cities, within an IOT context are projects that combine aspects of the physical
and digital worlds to provide infrastructure and
services. Inherently these projects have to tackle the challenge of
scalable software management as well as distributed data management i.e. Big Data.</p>

<p>Among the projects we are involved in are parking management
applications using parking sensors, real time analysis of pollution data from
pollution monitors and using telemetry data to map routes for people with
disabilities.</p>

<p>The problem space that connected devices are used in is diverse but
technologically speaking the architectural model is fairly common. There are usually
a number of different types of sensors each measuring distinct factors
which in turn are listened to by either other devices or
software services. In the parking situation, a connected car can
listen to sensors in a particular area in order to ascertain
the nearest parking availability.  Any serious IOT project will
quickly evolve to having thousands, if not millions, of devices
connected to it.  It will also need to be able to cope with potentially millions of listeners such as the
individual cars in the parking scenario.</p>

<h2>Architectural Model</h2>

<p>We strongly favour the Publish/Subscribe (aka PUB/SUB) model of
building software in IOT.  In pub/sub, &ldquo;Publishers&rdquo; are usually the
devices but can also be data from smart phones and the &ldquo;Subscribers&rdquo; are all the
services that care about the data that the device is emitting.  In the PUB/SUB
model devices can have one or many subscribers and subscribers
can listen to one or many publishers. This is essential when building
systems for Cities.  Let&rsquo;s take the example of pollution monitoring,
there are many potential groups interested in this data from environmental groups to those
concerned by the impact on health.  Each group should be free to build
applications that are relevant to them without being impacted by the
needs of the other subscribers.  You do not want a situation where
each pollution monitor can only talk to one monolytic, and
often proprietary, system thereby needing to set up another pollution monitor on
the same street for each group which is frankly impractical and
wasteful. The PUB/SUB model eliminates this situation.</p>

<p>Scaling this model has been our obsession since the start of
opensensors.IO.  We have open sourced our engine to enable others to
be able to also create scalable services. <a href="https://github.com/OpenSensorsIO/azondi">Azondi</a> is our
<a href="http://opensensors.io/">MQTT</a> based engine to enable processing device data at
scale.</p>

<p>All of this has been possible by standing on the shoulders of giants
using battle test components.  Our MQTT broker relies on <a href="http://netty.io/">Netty</a> in order to provide an extensible
broker.  Netty is used by a host of tech companies to build various
real time systems such as Twitter, Facebook and Avast.  We also rely on
<a href="https://github.com/reactor/reactor">Project Reactor</a> to get a non-blocking
dispatcher for event driven programming based on the
<a href="http://en.wikipedia.org/wiki/Reactor_pattern">Reactor Pattern</a>. This dispatcher acts as a kind of sorting office between devices and their
listeners. It receives all messages and &lsquo;delivers&rsquo; messages to
interested listeners.</p>

<p>The most important motivation behind the technological choices we made to build
Azondi is the need to avoid polling at all costs. When you have
potentially 100,000s of services listening to each device message you
never want a situation where you are being simultaneously hit by requests.</p>

<h2>Model of a City</h2>

<p>Putting the above theory into a real world model, below is a diagram
on how Azondi would be implemented in reality.  Let us pretend that we are processing device data from
disparate sources for the London Borough of Camden.</p>

<p>In the example, there are environmental monitors that measure
pollution and noise as well as a weather station monitoring temperature and
wind speeds.  In addition, cars send information about traffic
 in their vicinity. On the other hand, Mary&rsquo;s car is listening for local parking
information and Sophie&rsquo;s phone listens to information on noise,
pollution, temperature and energy readings.  Both Mary&rsquo;s car and Sophie
would have the option to filter the information they receive
i.e. local information only or when pollution hits dangerous levels.  Camden Council cares about all of the data sets and
would probably have a dashboard or a decision support system.</p>

<h2>Illustration of Azondi in action</h2>

<p>Click on each device to get it to publish (random) data and watch the
subscribers receive their information.</p>

<iframe src="http://city-model.s3-website-us-east-1.amazonaws.com/#"
height=800px width=900px scrolling = "no"></iframe>



]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Your First Post]]></title>
    <link href="http://blog.opensensors.io/blog/2013/12/28/lorem/"/>
    <updated>2013-12-28T15:49:17+00:00</updated>
    <id>http://blog.opensensors.io/blog/2013/12/28/lorem</id>
    <content type="html"><![CDATA[<p>This is a lipsum page to demonstrate the theme&rsquo;s typography. Modify this post to your heart&rsquo;s content &ndash; or simply delete it.</p>

<p>Lorem ipsum dolor sit amet, ut brute legimus honestatis cum. Eirmod verear mei ne, id falli conclusionemque est, autem populo duo et. Causae noluisse ex sed. Solet mentitum salutandi ad mei, vis ex esse prima nullam, tation melius aliquid pri ea. Minimum sententiae mei ad, mei et reque novum.</p>

<p>Eu nec eirmod inermis, nominavi deleniti electram ut mei. Veri quidam vivendum sit id, voluptaria percipitur deterruisset an nec. Mei mazim erroribus eu, his in errem nonumy comprehensam. Modo pericula duo id, te vis facete verear. Ex cum volutpat corrumpit aliquando, ad vim assentior argumentum temporibus.</p>

<p>Id est eros justo movet, duo eu alii vitae. Quo altera imperdiet efficiantur in, nec error iudico an. Sed an etiam consul, invenire platonem nam an. Nec an integre splendide, libris oportere duo ei. Has eu solet sententiae, ex nam noster tractatos, sonet patrioque nec ad.</p>

<p>An minim mollis mediocrem est, lucilius atomorum ex eum. Quaeque probatus qui cu, ut mutat dolorem epicurei pro, vel labores delicata rationibus et. Cu eos sumo inermis, viderer molestiae assueverit ius ad. Cum atqui error insolens in. Iuvaret adolescens referrentur cu pri.</p>

<p>Ei putant perfecto atomorum eos, an civibus hendrerit sit. Pri cu probo nominavi, et sea cetero hendrerit incorrupte. Amet unum prompta per at, impedit reprehendunt an cum, vix laudem dolorem at. Suas blandit molestie in eum.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The Big Red Button]]></title>
    <link href="http://blog.opensensors.io/blog/2013/11/25/the-big-red-button/"/>
    <updated>2013-11-25T23:48:00+00:00</updated>
    <id>http://blog.opensensors.io/blog/2013/11/25/the-big-red-button</id>
    <content type="html"><![CDATA[<p>I have a development harness for my Clojure systems called <a href="https://github.com/juxt/jig?source=c">Jig</a>. Jig has
a feature that allows me to teardown and reinitialize the entire state
of the system, while loading in any code that has changed since the last
reset. It allows for a rapid development experience approaching that of
Smalltalk and LISP systems a few decades ago.</p>

<p>Along with resets, there are other notable signals that are appropriate
for the ceremony of pushing a &lsquo;big red button&rsquo; (besides launching
missiles at your enemy!).</p>

<ul>
<li>signalling that a new code release should be deployed into production</li>
<li>telling your family that dinner is ready</li>
<li>instructing the quadrocopter to ignore all further signals from the
trainee pilot, level off and gracefully descend to the ground</li>
</ul>


<p><img src="http://blog.opensensors.io/images/Big_Red_Button.jpg" /></p>

<p>The Big Red Button at opensensors was bought from <a href="http://www.dreamcheeky.com/big-red-button">Dream Cheeky</a></p>

<h2>Installing Mosquitto</h2>

<p>As a pre-requisite, we&rsquo;ll need to install an MQTT client.</p>

<p>For this, install <em>mosquitto</em>, an open source MQTT broker which comes
with command-line client tools for publishing messages. Full
instructions are here: <a href="http://mosquitto.org/download/">http://mosquitto.org/download/</a></p>

<h2>Detect button presses in Linux</h2>

<p>The Big Red Button doesn&rsquo;t come with a dedicated Linux driver, so we
must write one. These instructions assume you&rsquo;re using Arch Linux, if
you&rsquo;re using a different distribution then you may have to adjust them
accordingly (file locations may be slightly different).</p>

<h3>Adding the ~/dev/big_red_button~</h3>

<p>First we need to create a Unix =/dev= character device that we can use to
communicate with the Big Red Button.</p>

<p>Plug the big red button into a spare USB port and run the command
=lsusb=. If your big red button is attached, you should an entry like
this :&ndash;</p>

<pre><code>$ lsusb
Bus 001 Device 003: ID 1d34:000d Dream Cheeky Dream Cheeky Big Red Button
</code></pre>

<p>We need to find the =ID_MODEL= of the device. We can do this by running
=udevadm= and try disconnecting and reconnecting the device.</p>

<pre><code># udevadm monitor --environment udev | grep ID_MODEL=
ID_MODEL=DL100B_Dream_Cheeky_Generic_Controller
ID_MODEL=DL100B_Dream_Cheeky_Generic_Controller
ID_MODEL=DL100B_Dream_Cheeky_Generic_Controller
</code></pre>

<p>Or we can find out with the =udevadm= command.</p>

<pre><code># udevadm info /dev/bus/usb/001/003
P: /devices/pci0000:00/0000:00:1a.0/usb1/1-1/1-1.3
N: bus/usb/001/061
S: big_red_button
E: BUSNUM=001
...
E: ID_MODEL=DL100B_Dream_Cheeky_Generic_Controller
</code></pre>

<p>In this case, 001 and 003 correspond to the Bus and Device returned by
=lsusb= respectively.</p>

<p>Now we can pattern match on that udev environment value. As root, create
a file =/etc/udev/rules.d/50-big-red-button.rules= with the following
content, making sure that the ENV{ID_MODEL} entry matches the correct
string that we&rsquo;ve just found using :&ndash;</p>

<pre><code>ACTION=="add", ENV{ID_MODEL}=="DL100B_Dream_Cheeky_Generic_Controller", SYMLINK+="big_red_button", MODE="0666", RUN+="/usr/bin/mosquitto_pub -h mqtt.opensensors.io -t /my/big/red/button -m Add"
ACTION=="remove", ENV{ID_MODEL}=="DL100B_Dream_Cheeky_Generic_Controller", RUN+="/usr/bin/mosquitto_pub -h mqtt.opensensors.io -t /my/big/red/button -m Add"
</code></pre>

<p>This causes a new device to be added, =~/dev/big_red_button~=, with a
mode of 666 so that we can read and write from it without being
root. Also, every time the device is connected and disconnected, MQTT
messages are published to the topic =/my/big/red/button= at
OpenSensorsIO. We&rsquo;ll use this topic for this example, but you should set
this to something unique.</p>

<p>Reload the udev rules with the following command :&ndash;</p>

<pre><code>udevadm control --reload-rules
</code></pre>

<p>To test, disconnect the big red button (pull out the USB plug) and
reconnect it. Each time you do this you should see the device
=~/dev/big_red_button~= disappear and reappear.</p>

<h3>Writing the device driver</h3>

<p>We need to write some simple code to control the device which will print events to standard out.</p>

<p>Copy and paste the following code into a file, for example, =~big-red-button.c~=</p>

<pre><code>/*
,* Copyright © 2013, Malcolm Sparks &lt;malcolm@congreve.com&gt;. All Rights Reserved.
,*
,* A program to convert USB firing events from the Dream Cheeky 'Big Red Button' to MQTT events.
,*/

#include &lt;fcntl.h&gt;
#include &lt;stdio.h&gt;
#include &lt;string.h&gt;
#include &lt;stdlib.h&gt;

#define LID_CLOSED 21
#define BUTTON_PRESSED 22
#define LID_OPEN 23

int main(int argc, char **argv)
{
  int fd;
  int i, res, desc_size = 0;
  char buf[256];

  /* Use a udev rule to make this device */
  fd = open("/dev/big_red_button", O_RDWR|O_NONBLOCK);

  if (fd &lt; 0) {
    perror("Unable to open device");
    return 1;
  }

  int prior = LID_CLOSED;

  while (1) {
    memset(buf, 0x0, sizeof(buf));
    buf[0] = 0x08;
    buf[7] = 0x02;

    res = write(fd, buf, 8);
    if (res &lt; 0) {
      perror("write");
      exit(1);
    }

    memset(buf, 0x0, sizeof(buf));
    res = read(fd, buf, 8);

    if (res &gt;= 0) {
      if (prior == LID_CLOSED &amp;&amp; buf[0] == LID_OPEN) {
         printf("Ready to fire!\n");
         fflush(stdout);
      } else if (prior != BUTTON_PRESSED &amp;&amp; buf[0] == BUTTON_PRESSED) {
        printf("Fire!\n");
        fflush(stdout);
      } else if (prior != LID_CLOSED &amp;&amp; buf[0] == LID_CLOSED) {
        printf("Stand down!\n");
        fflush(stdout);
      }
      prior = buf[0];
    }
    usleep(20000); /* Sleep for 20ms*/
  }
}
</code></pre>

<p>Compile the file</p>

<pre><code>$ cc big-red-button.c -o big-red-button
</code></pre>

<p>and run the executable, testing it by opening the lid on your device and pressing the (big red) button (a few times!). You should get output looking a bit like this :&ndash;</p>

<pre><code>$ ./big-red-button
Ready to fire!
Fire!
Fire!
Fire!
Fire!
Stand down!
</code></pre>

<p>If so, great, we now have a functioning device.</p>

<pre><code>$ ./big-red-button | mosquitto_pub -l -h mqtt.opensensors.io -t /my/big/red/button
</code></pre>

<p>Now go to <a href="http://opensensors.io">http://opensensors.io</a> and tune into the topic. Open the lid,
and start pressing the button. If you&rsquo;ve done everything correctly,
you&rsquo;ll see your messages in your browser.</p>

<p>Have fun!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Future Cities]]></title>
    <link href="http://blog.opensensors.io/blog/2013/10/08/future-cities/"/>
    <updated>2013-10-08T13:07:00+01:00</updated>
    <id>http://blog.opensensors.io/blog/2013/10/08/future-cities</id>
    <content type="html"><![CDATA[<p>We were honored to be a platform partner and host the data for <a href="http://futurecitieshackathon.com/">The Future Cities Hackathon: Open Urban Data for The Citizens</a> a collaborative project by <a href="http://datasciencelondon.org/">Data Science London</a> during the weekend of the 5th &ndash; 6th of October.</p>

<p>Granular Data sets where provided by the City of Westminster by street and a period of around a year.
The full list data sets are below:</p>

<ul>
<li>Anti Social Behavior data</li>
<li>Dog fouling</li>
<li>Graffiti</li>
<li>Parking Sensors</li>
<li>Parking Tickets issued</li>
<li>Crowd Dynamics data measuring foot falls once an hour</li>
<li>Parking Cashless transactions data</li>
</ul>


<p>Participants spent the weekend working on projects aimed to improve the experiences of City of Westminster residents.  There were approximately 15 submissions in order to win one of 3 prizes.  The prize categories were for Statistical modelling, Data Visualisation and a Windows phone application.  The quality of the final submissions were outstanding.</p>

<p>A few of the submissions were</p>

<ul>
<li><p>Team &lsquo;Fjölmenni&rsquo;, who won the Statistical modeling challenge, made a &lsquo;CrowdWalk&rsquo; application that predicted how busy streets would be by time and day.</p></li>
<li><p>Team &lsquo;Kung fu pandas&rsquo; made a number of statistical models on parking spaces, one of the most interesting was finding under utilized car parking spaces.</p></li>
</ul>


<p><img src="http://blog.opensensors.io/images/IMAG0731.jpg" /></p>

<ul>
<li>Team &lsquo;Street Sweep&rsquo; won the best Visualisation catergory and made a fantastic game 3d game using the opensensors.io api and open street map.  The game allowed players to clean dog fouling, vomit, etc from real data</li>
</ul>


<div class="embed-video-container"><iframe src="http://www.youtube.com/embed/jWkxDIYp6sU "></iframe></div>


<p>There were many more amazing projects submitted that could make the lives of people of Westminster so much easier.</p>

<h3>The Problem</h3>

<p>Unfortunately, getting the data in the first place was incredibly difficult.  The painful process and route that it took to get to us was described by Carlos in his talk.  The data was passsed between a multitude of intermediary companies and crossed the Oceans a few times in the below manner</p>

<p>&ldquo;Sensor device >  Data Provider > people > DB > people > ETL > people> CSV > public entity> people > ETL>  IT Vendor> DW > people > CSV > Sharepoint > Dropbox > and… us !!!&rdquo;</p>

<p>This process harms everyone from the council to residents. We can and need to simplify this process.</p>

<p>Smart environments need not be a dream of the distant future if we open the data and enable businesses and developers to build services for the benefit of everyone.</p>
]]></content>
  </entry>
  
</feed>
